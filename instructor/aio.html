<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Getting Started With Neuroimaging Analysis: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav IDEAS"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="IDEAS" src="../assets/images/IDEAS-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>

      </div>
    </div>
    <div class="selector-container">


      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav IDEAS" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="IDEAS" src="../assets/images/IDEAS-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Getting Started With Neuroimaging Analysis
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Getting Started With Neuroimaging Analysis
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Getting Started With Neuroimaging Analysis
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress IDEAS">
    <div class="progress-bar IDEAS" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="imaging-data-structure-and-formats.html">1. Imaging Data: Structure And Formats</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="structural-mri.html">2. Structural MRI: Bias Correction, Segmentation and Image Registration</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="pet-imaging.html">3. Processing and analysing PET brain images</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="diffusion-weighted-imaging.html">4. Diffusion-weighted imaging (DWI)</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="functional-mri.html">5. Functional Magnetic Resonance Imaging (fMRI)</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="command-line.html">6. Extra: Using the Command Line</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-imaging-data-structure-and-formats"><p>Content from <a href="imaging-data-structure-and-formats.html">Imaging Data: Structure And Formats</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/imaging-data-structure-and-formats.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 32 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How is imaging data represented in a computer?</li>
<li>What are some of the popular imaging formats used?</li>
<li>How do I view and navigate around an image/</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Describe the structure of imaging data</li>
<li>Understand the coordinate systems and mapping between voxels and
real world.</li>
<li>Demonstrate how to view images, navigate through volumes and change
contrast</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>Any medical image consists of two parts: a <strong>header</strong>
and the <strong>image</strong> itself. The header consists of metadata
that describe the image. This includes the patient’s demographic
information such as the patient’s name, age, gender, and date of birth.
The header also gives information on the image characteristics such as
image dimension and some acquisition parameters. Because of the need to
store more information, medical images require specific formats
(different from e.g. .jpeg or .png).</p>
<div class="section level3">
<h3 id="image-formats-dicom-and-nifti">Image formats: DICOM and NIfTI<a class="anchor" aria-label="anchor" href="#image-formats-dicom-and-nifti"></a>
</h3>
<p><strong>DICOM (.dcm)</strong> stands for Digital Imaging and
Communications in Medicine. It is a standard, internationally accepted
format to view, store, retrieve and share medical images. Clinical
imaging data are typically stored and transferred in the DICOM format,
so DICOM can be considered the native format in which we get imaging
data from the scanner.</p>
<p><strong>NIfTI (.nii, .nii.gz)</strong> format is simpler and easier
to support, so has been widely adopted by scientists in the neuroimaging
community. Therefore, a vital initial step in processing the data is to
convert images from DICOM to NIfTI format. In this practical we will
work with data that have already been converted to NIfTI, but many tools
for such conversions are available (for example <a href="https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage" class="external-link">dcm2niix</a>).</p>
</div>
<div class="section level3">
<h3 id="viewing-image-properties---fslhd-and-fslinfo">Viewing image properties - fslhd and fslinfo<a class="anchor" aria-label="anchor" href="#viewing-image-properties---fslhd-and-fslinfo"></a>
</h3>
<p>These tools enable various properties of an image to be viewed.</p>
<p>Clicking on the Applications in the upper left-hand corner and select
the terminal icon. This will open a terminal window that you will use to
type commands <img src="../fig/aic_smri_launch_terminal.png" alt="Launch terminal window" class="figure"></p>
<p>From the terminal window type:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/ImageDataVisualization</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">ls</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>sub-OAS30015_acq-TSE_T2w.json            sub-OAS30015_T1w_brain_seg.nii.gz
sub-OAS30015_acq-TSE_T2w.nii.gz          sub-OAS30015_T1w.json
sub-OAS30015_T1w_brain_mask.nii.gz       sub-OAS30015_T1w.nii.gz
sub-OAS30015_T1w_brain_mixeltype.nii.gz  sub-OAS30015_T1w_orig.nii.gz
sub-OAS30015_T1w_brain.nii.gz            sub-OAS30015_T2star.json
sub-OAS30015_T1w_brain_pve_0.nii.gz      sub-OAS30015_T2star.nii.gz
sub-OAS30015_T1w_brain_pve_1.nii.gz      sub-OAS30015_T2w.json
sub-OAS30015_T1w_brain_pve_2.nii.gz      sub-OAS30015_T2w.nii.gz
sub-OAS30015_T1w_brain_pveseg.nii.gz</code></pre>
</div>
<p>This means that we are going to be working in the
<code>ImageDataVisualization</code> subfolder under <code>data</code> in
your home directory (<code>~</code>). The <code>ls</code> command gives
you a list of the files in this directory.</p>
<p>Type</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">fslhd</span> sub-OAS30015_T1w.nii.gz</span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Let’s look at the output </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>filename	sub-OAS30015_T1w.nii.gz

sizeof_hdr	348
data_type	INT16
dim0		3
dim1		176
dim2		256
dim3		170
dim4		1
dim5		1
dim6		1
dim7		1
vox_units	mm
time_units	s
datatype	4
nbyper		2
bitpix		16
pixdim0		1.000000
pixdim1		1.000003
pixdim2		1.000000
pixdim3		1.000000
pixdim4		2.400000
pixdim5		0.000000
pixdim6		0.000000
pixdim7		0.000000
vox_offset	352
cal_max		0.000000
cal_min		0.000000
scl_slope	1.000000
scl_inter	0.000000
phase_dim	0
freq_dim	0
slice_dim	0
slice_name	Unknown
slice_code	0
slice_start	0
slice_end	0
slice_duration	0.000000
toffset		0.000000
intent		Unknown
intent_code	0
intent_name	
intent_p1	0.000000
intent_p2	0.000000
intent_p3	0.000000
qform_name	Scanner Anat
qform_code	1
qto_xyz:1	0.999466 -0.000520 -0.032767 -73.860321
qto_xyz:2	-0.000059 0.999844 -0.017685 -88.219193
qto_xyz:3	0.032771 0.017677 0.999307 -94.454788
qto_xyz:4	0.000000 0.000000 0.000000 1.000000
qform_xorient	Left-to-Right
qform_yorient	Posterior-to-Anterior
qform_zorient	Inferior-to-Superior
sform_name	Scanner Anat
sform_code	1
sto_xyz:1	0.999466 -0.000520 -0.032767 -73.860321
sto_xyz:2	-0.000059 0.999844 -0.017685 -88.219193
sto_xyz:3	0.032771 0.017677 0.999307 -94.454788
sto_xyz:4	0.000000 0.000000 0.000000 1.000000
sform_xorient	Left-to-Right
sform_yorient	Posterior-to-Anterior
sform_zorient	Inferior-to-Superior
file_type	NIFTI-1+
file_code	1
descrip		6.0.5:9e026117
aux_file	OAS30015_MR_d2004</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">fslhd</span> sub-OAS30015_T1w_brain_pve_0.nii.gz</span></code></pre>
</div>
<div id="accordionSpoiler2" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler2" aria-expanded="false" aria-controls="collapseSpoiler2">
  <h3 class="accordion-header" id="headingSpoiler2">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Let’s look at the output </h3>
</button>
<div id="collapseSpoiler2" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler2" aria-labelledby="headingSpoiler2">
<div class="accordion-body">
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>filename	sub-OAS30015_T1w_brain_pve_0.nii.gz

sizeof_hdr	348
data_type	FLOAT32
dim0		3
dim1		176
dim2		256
dim3		170
dim4		1
dim5		1
dim6		1
dim7		1
vox_units	mm
time_units	s
datatype	16
nbyper		4
bitpix		32
pixdim0		1.000000
pixdim1		1.000003
pixdim2		1.000000
pixdim3		1.000000
pixdim4		2.400000
pixdim5		0.000000
pixdim6		0.000000
pixdim7		0.000000
vox_offset	352
cal_max		0.000000
cal_min		0.000000
scl_slope	1.000000
scl_inter	0.000000
phase_dim	0
freq_dim	0
slice_dim	0
slice_name	Unknown
slice_code	0
slice_start	0
slice_end	0
slice_duration	0.000000
toffset		0.000000
intent		Unknown
intent_code	0
intent_name	
intent_p1	0.000000
intent_p2	0.000000
intent_p3	0.000000
qform_name	Scanner Anat
qform_code	1
qto_xyz:1	0.999466 -0.000520 -0.032767 -73.860321
qto_xyz:2	-0.000059 0.999844 -0.017685 -88.219193
qto_xyz:3	0.032771 0.017677 0.999307 -94.454788
qto_xyz:4	0.000000 0.000000 0.000000 1.000000
qform_xorient	Left-to-Right
qform_yorient	Posterior-to-Anterior
qform_zorient	Inferior-to-Superior
sform_name	Scanner Anat
sform_code	1
sto_xyz:1	0.999466 -0.000520 -0.032767 -73.860321
sto_xyz:2	-0.000059 0.999844 -0.017685 -88.219193
sto_xyz:3	0.032771 0.017677 0.999307 -94.454788
sto_xyz:4	0.000000 0.000000 0.000000 1.000000
sform_xorient	Left-to-Right
sform_yorient	Posterior-to-Anterior
sform_zorient	Inferior-to-Superior
file_type	NIFTI-1+
file_code	1
descrip		6.0.5:9e026117
aux_file	OAS30015_MR_d2004</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Let’s look at the most important fields:</p>
<ul>
<li>
<strong>Data type</strong> (<code>data_type</code>): Note that some
images (<code>sub-OAS30015_T1w</code>) are of <em>integer</em> datatype,
while others (<code>sub-OAS30015_T1w_brain_pve_0</code>) are of
<em>floating point</em> datatype. Integer means that the intensity
values can only take on whole numbers - no fractions - raw image data is
normally of this type. Floating point means that intensity values can be
fractional - the result of applying most statistical processing
algorithms to image data results in images of floating point type.</li>
<li>
<strong>Image dimension</strong> (<code>dim1</code>,
<code>dim2</code>,<code>dim3</code>): this is the number of voxels in
the image in the x,y,z dimension. This means that we have a cube of
imaging data in the file that contains <code>dim1</code> columns,
<code>dim2</code> rows, and <code>dim3</code> slices.</li>
<li>
<strong>Image resolution (Voxel size)</strong>
(<code>pixdim1</code>,<code>pixdim2</code>,<code>pixdim3</code>) : this
tells us the size that each voxel represents (in mm) in the x,y,z
dimension.</li>
</ul>
<p><em>As an example to understand the difference between image
dimension and image resolution, an MRI of a fruit fly or an elephant
could contain 256 slices (same <code>dim3</code> value), but one image
would have to represent a much larger size in the real world than the
other (different <code>pixdim3</code>).</em></p>
<div id="accordionInstructor1" class="accordion instructor-note accordion-flush">
<div class="accordion-item">
<button class="accordion-button instructor-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseInstructor1" aria-expanded="false" aria-controls="collapseInstructor1">
  <h3 class="accordion-header" id="headingInstructor1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="edit-2"></i></div> Instructor Note </h3>
</button>
<div id="collapseInstructor1" class="accordion-collapse collapse" data-bs-parent="#accordionInstructor1" aria-labelledby="headingInstructor1">
<div class="accordion-body">
<p>If the voxel dimension is the same in all directions (e.g. 1x1x1 mm)
we talk about <em>isotropic</em> voxels. Having images with isotropic
(or with very similar voxel size in the 3 directions) is desirable to
perform reliable quantitative analyses.</p>
</div>
</div>
</div>
</div>
<ul>
<li>
<strong>Affine transformation</strong> (<code>qform</code>): this
field encodes a transformation or mapping that tells us <strong>how to
convert the voxel location (i,j,k) to the real-world coordinates
(x,y,z)</strong> (i.e. the coordinate system of the MRI scanner in which
the image was acquired). The real-world coordinate system tends to be
defined according to the patient. The x-axis tends to go from patient
left to patient right, the y axis tends to go from anterior to
posterior, and the z-axis goes from top to bottom of the patient. This
mapping is very important, as this information will be needed to
correctly visualize images and also to align them later. <img src="../fig/coordinates_affine.png" alt="Coordinate systems" class="figure"> Figure from
<a href="https://slicer.readthedocs.io/en/latest/user_guide/coordinate_systems.html" class="external-link">Slicer</a>
</li>
</ul>
<p>An alternative command to <code>fslinfo</code> is <code>fslhd</code>,
which displays a reduced set of properties about the images (mainly data
type, dimension and resolution).</p>
</div>
</section><section><h2 class="section-heading" id="neuroimaging-data-analysis">Neuroimaging data analysis<a class="anchor" aria-label="anchor" href="#neuroimaging-data-analysis"></a>
<a class="anchor" aria-label="anchor" href="#neuroimaging-data-analysis"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="generic-blueprint-of-a-neuroimaging-study">Generic blueprint of a neuroimaging study<a class="anchor" aria-label="anchor" href="#generic-blueprint-of-a-neuroimaging-study"></a>
</h3>
<p>The steps to conduct a neuroimaging study are very similar to any
other scientific experiment. As we go through the workshop today, think
about where a certain analysis or tool falls in this generic
pipeline:</p>
<table class="table">
<colgroup>
<col width="16%">
<col width="33%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>Step</th>
<th>Aim</th>
<th>Challenges and considerations</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>1. Data Acquisition</strong></td>
<td>Obtain good quality and consistent data</td>
<td>Trade offs often necessary (e.g. time vs resolution). Optimize
protocol for your research aim. We will use already acquired data from
OASIS.</td>
</tr>
<tr class="even">
<td><strong>2. Data preprocessing</strong></td>
<td>Reduce noise and prepare data for further analysis</td>
<td>Some steps are common across modalities (e.g. brain extraction,
registration), others are modality-specific (e.g. motion correction,
distortion correction). Requires careful checking.</td>
</tr>
<tr class="odd">
<td><strong>3. Single-subject analysis</strong></td>
<td>Obtain measure of interest for each subject (often an image)</td>
<td>Modality-specific. Examples of single-subject outputs are
tissue-type segmentation maps, fractional anisotropy map.</td>
</tr>
<tr class="even">
<td><strong>4. Group-level analysis</strong></td>
<td>Compare single-subject results across groups</td>
<td>Common step across modalities. Usually happens in standard space
(i.e. after images from all subjects have been aligned to a reference
image, called <em>template</em>).</td>
</tr>
<tr class="odd">
<td><strong>5. Statistical inference</strong></td>
<td>Test reliability of results and generalizability to the
population</td>
<td>Common across modalities.</td>
</tr>
</tbody>
</table>
</div>
<div class="section level3">
<h3 id="neuroimaging-data-organization---brain-imaging-data-structure-bids">Neuroimaging data organization - Brain Imaging Data Structure
(BIDS)<a class="anchor" aria-label="anchor" href="#neuroimaging-data-organization---brain-imaging-data-structure-bids"></a>
</h3>
<p>Neuroimaging experiments usually generate multiple images and
non-imaging data. This can result in complicated data that can be
arranged in many different ways. Despite the structure of a neuroimaging
study is fairly standard, so far there is no consensus on how to
organize and share data obtained in neuroimaging experiments. The <a href="https://bids.neuroimaging.io/get_started.html" class="external-link">Brain Imaging Data
Structure (BIDS)</a> is a framework for organizing data in a
standardized way.</p>
<p>The main specifications regard how to structure data/metadata within
a hierarchy of folders and how to name files. The data you will use in
this workshop will mostly be organized according to this standard. If
you are interested, you can find the details of these specifications in
the <a href="https://bids-standard.github.io/bids-starter-kit/index.html" class="external-link">BIDS
starter kit</a>.</p>
</div>
</section><section><h2 class="section-heading" id="visualizing-neuroimaging-data---fsleyes">Visualizing neuroimaging data - FSLeyes<a class="anchor" aria-label="anchor" href="#visualizing-neuroimaging-data---fsleyes"></a>
<a class="anchor" aria-label="anchor" href="#visualizing-neuroimaging-data---fsleyes"></a>
</h2>
<hr class="half-width">
<p>FSLeyes (pronounced <strong>fossilize</strong>) is the FSL image
viewer for 3D and 4D data. It does not perform any processing or
analysis of images - that is done by separate tools. FSLeyes has lots of
features to visualize data and results in a variety of useful ways, and
some of these are shown in this introductory practical.</p>
<p>Here we provide a quick introduction to some FSLeyes features that
you will be likely to use throughout the workshop, while other more
specific features will be introduced at a later point. If you are
already familiar with FSLeyes, feel free to skip this part and move on
to another section of the workshop.</p>
<p>For a full overview of what FSLeyes can do, take a look at the <a href="https://open.win.ox.ac.uk/pages/fsl/fsleyes/fsleyes/userdoc/index.html" class="external-link">FSLeyes
user guide</a>.</p>
<div class="section level3">
<h3 id="getting-started">Getting started<a class="anchor" aria-label="anchor" href="#getting-started"></a>
</h3>
<p>Assuming you are still in the
<code>~/data/ImageDataVisualization</code> directory,</p>
<p>Start FSLeyes by typing in the terminal:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">fsleyes</span> <span class="kw">&amp;</span></span></code></pre>
</div>
<p>The <code>&amp;</code> means that the program you asked for
(<code>fsleyes</code>) runs in the background in the terminal (or
shell), and you can keep typing and running other commands while fsleyes
continues to run. If you had not made <code>fsleyes</code> run in the
background (i.e., if you had just typed <code>fsleyes</code> without the
<code>&amp;</code> at the end) then you would not be able to get
anything to run in that terminal until you killed <code>fsleyes</code>
(although you could still type things, but they would not run).</p>
</div>
<div class="section level3">
<h3 id="basic-image-viewing">Basic image viewing<a class="anchor" aria-label="anchor" href="#basic-image-viewing"></a>
</h3>
<p>FSLeyes by defaults opens in the <em>ortho view</em> mode. If you add
image filenames on the command line (after typing <code>fsleyes</code>)
it will load them all automatically, and you can also add many options
from the command line. FSLeyes assumes that all of the images which you
load share a single coordinate system, but images do not have to have
the same field of view, number of voxels, or timepoints.</p>
<p>In FSLeyes, load in the image <code>sub-OAS30015_T1w.nii.gz</code>,
by pressing <em>File &gt; Add from file</em> and selecting the image.
This image is a structural MRI T1-weighted scan.</p>
<p>Hold the mouse button down in one of the ortho canvases and move it
around - see how various things update as you do so:</p>
<ul>
<li>the other canvases update their view</li>
<li>the cursor’s position in both voxel and mm co-ordinates gets
updated</li>
<li>the image intensity at the cursor is shown</li>
</ul>
</div>
<div class="section level3">
<h3 id="navigating-in-an-ortho-view">Navigating in an ortho view<a class="anchor" aria-label="anchor" href="#navigating-in-an-ortho-view"></a>
</h3>
<p>You can interact with an orthographic view in a number of ways. Spend
a couple of minutes trying each of these.</p>
<ul>
<li>Click, or click and drag on a canvas, to change the current
location.</li>
<li>Right click and drag on a canvas to draw a zoom rectangle. When you
release the mouse, the canvas will zoom in to that rectangle.</li>
<li>Hold down the ⌘ key (OSX) or CTRL key (Linux), and use your mouse
wheel to zoom in and out of a canvas.</li>
<li>Hold down the ⇧ key, and use your mouse wheel to change the current
location along the depth axis (change the displayed slice) for that
canvas.</li>
<li>You can middle-click and drag, or hold down the ALT key and drag
with the left mouse button, to pan around.</li>
</ul>
</div>
<div class="section level3">
<h3 id="the-display-toolbar">The display toolbar<a class="anchor" aria-label="anchor" href="#the-display-toolbar"></a>
</h3>
<p><img src="../fig/display_toolbar.png" alt="Display toolbar" height="180" class="figure"> The display toolbar allows you to adjust the display
properties of the currently selected image. Play around with the
controls and note how the image display changes (but leave the “overlay
type” as “3D/4D volume”).</p>
<p>The word “overlay” is interchangeable with “image”. FSLeyes uses
“overlay” because it can also load some other non-image file types such
as surface images.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Overlay display panel:</strong> Clicking on the gear button
( <img src="../fig/gear_icon.png" alt="gear icon" height="24" class="figure"> ) opens a
panel with more display settings.</li>
<li>
<strong>Overlay information:</strong> Clicking on the information
button ( <img src="../fig/information_icon.png" alt="info" height="24" class="figure"> )
opens a panel with information about the image.</li>
<li>
<strong>Overlay name:</strong> You can change the image name here
(for display purpose only, it will not change the actual filename).</li>
<li>
<strong>Overlay type:</strong> FSLeyes allows some images to be
displayed in different ways. This should be set to “3D/4D volume” most
of the time.</li>
<li>
<strong>Opacity:</strong> Adjust the opacity (transparency)
here.</li>
<li>
<strong>Brightness/contrast:</strong> Quickly adjust the image
brightness and contrast here.</li>
<li>
<strong>Display range:</strong> Use these fields for fine-grained
control over how the image data is coloured, instead of using the
brightness and contrast sliders.</li>
<li>
<strong>Colour map:</strong> Choose from several different colour
maps.</li>
<li>
<strong>Enable -ve colour map:</strong> If you are viewing an image
that has both positive and negative values, this button allows you to
enable a colour map that is used for the negative values.</li>
<li>
<strong>-ve colour map:</strong> Choose a colour map for negative
values here.</li>
</ol>
<p>If FSLeyes does not have enough room to display a toolbar in full, it
will display left and right arrows ( <img src="../fig/toolbar_left.png" alt="left" height="24" class="figure"> ), ( <img src="../fig/toolbar_right.png" alt="right" height="24" class="figure"> ) on each side of the toolbar - you can click
on these arrows to navigate back and forth through the toolbar.</p>
</div>
<div class="section level3">
<h3 id="the-ortho-toolbar">The ortho toolbar<a class="anchor" aria-label="anchor" href="#the-ortho-toolbar"></a>
</h3>
<figure><img src="../fig/ortho_toolbar.png" alt="Ortho toolbar" height="160" class="figure mx-auto d-block"></figure><p>The ortho toolbar allows you to adjust and control the ortho view.
Play with the controls, and try to figure out what each of them do.</p>
<ol style="list-style-type: decimal">
<li>
<strong>View settings panel</strong> <img src="../fig/spanner_icon.png" alt="spanner icon" height="24" class="figure"> : Clicking on the spanner button opens
panel with advanced ortho view settings.</li>
<li>
<strong>Screenshot</strong> <img src="../fig/camera_icon.png" alt="screenshot icon" height="24" class="figure"> : Clicking on the camera button
will allow you to save the current scene, in this ortho view, to an
image file.</li>
<li>
<strong>Toggle canvases</strong> <img src="../fig/sagittal_icon.png" alt="sagittal icon" height="24" class="figure"> , <img src="../fig/coronal_icon.png" alt="coronal icon" height="24" class="figure"> , <img src="../fig/axial_icon.png" alt="axial icon" height="24" class="figure"> : These three buttons allow you to
toggle each of the three canvases on the ortho view.</li>
<li>
<strong>Canvas layout</strong> <img src="../fig/horizontal_icon.png" alt="horizontal icon" height="24" class="figure"> , <img src="../fig/vertical_icon.png" alt="vertical icon" height="24" class="figure"> , <img src="../fig/grid_icon.png" alt="grid icon" height="24" class="figure"> : These three buttons allow you to choose
between laying out the canvases horizontally (<img src="../fig/horizontal_icon.png" alt="horizontal icon" height="24" class="figure"> ),
vertically (<img src="../fig/vertical_icon.png" alt="vertical icon" height="24" class="figure"> ), or in a grid (<img src="../fig/grid_icon.png" alt="grid icon" height="24" class="figure"> ).</li>
<li>
<strong>Movie mode</strong> <img src="../fig/movie_icon.png" alt="movie icon" height="24" class="figure"> : This button enables <em>movie
mode</em> - if you load a 4D image, and turn on movie mode, the image
will be “played” as a movie (the view will loop through each of the 3D
images in the 4D volume).</li>
<li>
<strong>Toggle cursor/labels</strong> <img src="../fig/plus_icon.png" alt="add icon" height="24" class="figure"> : This button allows you to toggle the
anatomical labels and location cursor on and off.</li>
<li>
<strong>Reset zoom</strong> <img src="../fig/reset_zoom_icon.png" alt="add icon" height="24" class="figure"> : This button resets the zoom level to
100% on all three canvases.</li>
<li>
<strong>Zoom slider:</strong> Change the zoom level on all three
canvases with this slider.</li>
</ol>
</div>
<div class="section level3">
<h3 id="multiple-views-lightbox">Multiple views: lightbox<a class="anchor" aria-label="anchor" href="#multiple-views-lightbox"></a>
</h3>
<p>Open a <em>lightbox</em> view using <em>View &gt; Lightbox View</em>.
If you drag the mouse around in the viewer you can see that the cursor
position is linked in the two views of the data (the ortho and the
lightbox views). This is particularly useful when you have several
images loaded in at the same time (you can view each in a separate view
window and move around all of them simultaneously). <img src="../fig/lightbox_toolbar.png" alt="Lightbox toolbar" height="210" class="figure"></p>
<p>The lightbox view has a slightly different toolbar to the ortho
toolbar.</p>
<ol style="list-style-type: decimal">
<li>
<strong>View settings panel</strong> <img src="../fig/spanner_icon.png" alt="spanner icon" height="24" class="figure"> : Clicking on the spanner button opens
a panel with advanced lightbox view settings.</li>
<li>
<strong>Screenshot</strong> <img src="../fig/camera_icon.png" alt="screenshot icon" height="24" class="figure"> : Clicking on the camera button
will allow you to save the current scene, in this lightbox view, to an
image file.</li>
<li>
<strong>Z axis</strong> <img src="../fig/sagittal_icon.png" alt="sagittal icon" height="24" class="figure"> , <img src="../fig/coronal_icon.png" alt="coronal icon" height="24" class="figure"> , <img src="../fig/axial_icon.png" alt="axial icon" height="24" class="figure"> : These three buttons allow you to
choose which slice plane to display in the lightbox view.</li>
<li>
<strong>Movie mode</strong> <img src="../fig/movie_icon.png" alt="movie icon" height="24" class="figure"> : This button enables movie mode.</li>
<li>
<strong>Slice range:</strong> These sliders allow you to control the
beginning and end points of the slices that are displayed.</li>
<li>
<strong>Zoom:</strong> This slicer allows you to control how many
slices are displayed on the lightbox view.</li>
<li>
<strong>Slice spacing:</strong> This slider allows you to control
the spacing between consecutive slices.</li>
</ol>
</div>
<div class="section level3">
<h3 id="unlinking-cursors">Unlinking cursors<a class="anchor" aria-label="anchor" href="#unlinking-cursors"></a>
</h3>
<p>You can “unlink” the cursor position between the two views (it is
linked by default). Go into one of the views, e.g., the lightbox view,
and press the spanner button ( <img src="../fig/spanner_icon.png" alt="spanner icon" height="24" class="figure"> ). This will open the lightbox view
settings panel. Turn off the <strong>Link Location</strong> option, and
close the view settings panel. You will now find that this view (the
lightbox view) is no longer linked to the “global” cursor position, and
you can move the cursor independently (in this view) from where it is in
the other views.</p>
<p>Close the lightbox view for now (click on the small red circle or X
at the very top of the view).</p>
</div>
</section><section><h2 class="section-heading" id="viewing-multiple-images">Viewing multiple images<a class="anchor" aria-label="anchor" href="#viewing-multiple-images"></a>
<a class="anchor" aria-label="anchor" href="#viewing-multiple-images"></a>
</h2>
<hr class="half-width">
<p>Now load in a second image
(<code>sub-OAS30015_T1w_brain_pve_0.nii.gz</code>) using <em>File &gt;
Add from file</em>. This image is a tissue segmentation image of the
cerebrospinal fluid. In the bottom-left panel is a list of loaded images
- the <em>overlay list</em>. <img src="../fig/overlay_list_oasis.png" alt="Overlay list" height="150" class="figure"></p>
<p>The overlay list shows the images which are currently loaded into
FSLeyes. When you select an image in this list, it becomes the
<strong>currently selected</strong> image - in FSLeyes, you can only
select one image at a time.</p>
<p>You can use the controls on the display toolbar to adjust the display
properties of the currently selected image. Select the image you just
loaded (<code>sub-OAS30015_T1w_brain_pve_0.nii.gz</code>), and use the
display toolbar to change its colour map to <em>Red-yellow</em>.</p>
<p>The overlay list allows you to do the following:</p>
<ul>
<li>Change the currently selected overlay, by clicking on the overlay
name.</li>
<li>Identify the currently selected overlay (highlighted in blue).</li>
<li>Add/remove overlays with the + and - buttons.</li>
<li>Change the overlay display order with the ▲ and ▼ buttons.</li>
<li>Show/hide each overlay with the eye button ( <img src="../fig/eye_icon.png" alt="eye icon" height="24" class="figure"> ), or by double
clicking on the overlay name.</li>
<li>Link overlay display properties with the chainlink button ( <img src="../fig/chainlink_icon.png" alt="chain icon" height="24" class="figure"> ).</li>
<li>Save an overlay if it has been edited, with the floppy disk button (
<img src="../fig/floppy_disk_icon.png" alt="disk icon" height="24" class="figure">
).</li>
<li>Left-click and hold the mouse button down on the overlay name to
view the overlay source (e.g. its location in the file system).</li>
</ul></section><section><h2 class="section-heading" id="image-information">Image information<a class="anchor" aria-label="anchor" href="#image-information"></a>
<a class="anchor" aria-label="anchor" href="#image-information"></a>
</h2>
<hr class="half-width">
<p>In the bottom right corner of the FSLeyes window you will find the
location panel, which contains information about the current cursor
location, and image data values at that location. <img src="../fig/location_panel_oasis.png" alt="Location panel" height="140" class="figure"></p>
<p>The controls on the left show the cursor location in <strong>world
coordinates</strong> (millimetres). This coordinate system will change
depending upon whether your image is in native subject space (scanner
anatomical coordinates), standard template coordinates (e.g. MNI152), or
some other coordinate space.</p>
<p>The controls in the middle show the cursor location in <strong>voxel
coordinates</strong>, relative to the currently selected image. If the
currently selected image is 4D (e.g. a time series image), the bottom
control displays the currently selected volume (e.g. time point).</p>
<p>The area on the right displays the intensity value and voxel location
at the current cursor location for all loaded images. Note that if you
have images with different resolutions loaded, the voxel location will
be different for each of them.</p>
</section><section><h2 class="section-heading" id="viewing-atlases">Viewing Atlases<a class="anchor" aria-label="anchor" href="#viewing-atlases"></a>
<a class="anchor" aria-label="anchor" href="#viewing-atlases"></a>
</h2>
<hr class="half-width">
<p>It is often useful to look at images in standard space. This means
that images are aligned (<em>registered</em>) to a reference template so
that each coordinate corresponds to the same point in the brain in all
images. This allows to perform group level analyses.</p>
<p>Let’s have a look at one of the most used templates, the MNI152.</p>
<ul>
<li>
<p>Unload all the images from <code>fsleyes</code> clicking on the
minus (<code>-</code>) icon in the Overlay list panel (or open a new
instance if you closed it before), press <em>File &gt; Add standard</em>
and select the image <code>MNI152_T1_1mm</code>.</p>
<p>As you can see it looks very similar to the T1w image we looked at
earlier. This is basically an <em>average T1w</em>.</p>
<p>Because we are in standard space, we can turn on the atlas tools with
<em>Settings &gt; Ortho View 1 &gt; Atlases</em>.</p>
</li>
<li>
<p>Now as you click around in the image you can see reporting of the
probability of being in different brain structures. You might want to
resize the different FSLeyes panels to increase the size of the Atlas
information space (in general you do this by dragging around the edges
of the different FSLeyes panels).</p>
<p>The atlas panel is organized into three main sections - <em>Atlas
information</em>, <em>Atlas search</em>, and <em>Atlas management</em>.
These sections are accessed by clicking on the tabs at the top of the
panel. We will only cover the first two sections in this introductory
practical.</p>
</li>
</ul>
<div class="section level3">
<h3 id="atlas-information">Atlas information<a class="anchor" aria-label="anchor" href="#atlas-information"></a>
</h3>
<p>The <strong>Atlas information</strong> tab displays information about
the current display location, relative to one or more atlases: <img src="../fig/atlas_info_panel.png" alt="Atlas information panel" height="200" class="figure"> The list on the left allows you to select the atlases
that you wish to query - click the check boxes to the left of an atlas
to toggle information on and off for that atlas. The
<strong>Harvard-Oxford cortical</strong> and
<strong>sub-cortical</strong> structural atlases are both selected by
default. These are formed by averaging careful hand segmentations of
structural images of many separate individuals.</p>
<p>The panel on the right displays information about the current display
location from each selected atlas. For probabilistic atlases, the
region(s) corresponding to the display location are listed, along with
their probabilities. For discrete atlases, the region at the current
location is listed.</p>
<p>You may click on the <strong>Show/Hide</strong> links alongside each
atlas and region name to toggle corresponding atlas images on and
off.</p>
</div>
<div class="section level3">
<h3 id="atlas-search">Atlas search<a class="anchor" aria-label="anchor" href="#atlas-search"></a>
</h3>
<p>The <strong>Atlas search</strong> tab allows you to browse through
the atlases, and search for specific regions. <img src="../fig/atlas_search_panel.png" alt="Atlas search panel" height="200" class="figure"></p>
<p>The list on the left displays all available atlases - the checkbox to
the left of each atlas toggles an image for that atlas on and off.</p>
<p>When you select an atlas in this list, all of the regions in that
atlas are listed in the area to the right. Again, the checkbox to the
left of each region name toggles an image for that region on and off.
The + button next to each region moves the display location to the
(approximate) centre of that region.</p>
<p>The search field at the top of the region list allows you to filter
the regions that are displayed. <img src="../fig/atlas_region_search.png" alt="Atlas region search" height="200" class="figure"></p>
<p>When you type some characters into the search field, the region list
will be filtered, so that only those regions with a name that contains
the characters you entered are displayed. The atlas list on the left
will also be updated so that any atlases which contain regions matching
the search term are highlighted in <strong>bold</strong>.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>Use the atlas search feature to locate the thalamus (left or
right).</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Here are the screenshots you should see: <img src="../fig/aic_imdata_fsl_lthal.png" alt="Left Thalamus" width="800" class="figure"></p>
<figure><img src="../fig/aic_imdata_fsl_rthal.png" alt="Right Thalamus" width="800" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
<p>For more information about the atlases available please refer to the
<a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases" class="external-link">FSL
Wiki</a>.</p>
<p>Quit FSLeyes when you have finished looking at the atlases.</p>
<div id="bonus-exercise-viewing-different-imaging-modalities" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="bonus-exercise-viewing-different-imaging-modalities" class="callout-inner">
<h3 class="callout-title">BONUS EXERCISE: Viewing different imaging modalities<a class="anchor" aria-label="anchor" href="#bonus-exercise-viewing-different-imaging-modalities"></a>
</h3>
<div class="callout-content">
<p>So far we have seen examples of MRI T1-weighted scans (T1w). In
research as well as in clinical setting, we acquire multiple imaging
modalities from the same individual to look at different brain
characteristics. Even if we acquire all the modalities in the same
session, the images may differ in orientation and resolution.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/ExtraStructuralMRI</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="fu">ls</span></span></code></pre>
</div>
<p>Let’s take two imaging modalities from a different participant:
<code>sub-OAS30003_T1w.nii.gz</code> and
<code>sub-OAS30003_FLAIR.nii.gz</code></p>
<ul>
<li><em>Do they have the same dimension?</em></li>
<li><em>Do they have the same resolution?</em></li>
</ul>
<p>Now let’s have a look at them in FSLeyes:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">fsleyes</span> sub-OAS30003_T1w.nii.gz sub-OAS30003_FLAIR.nii.gz</span></code></pre>
</div>
<p>Change the intensity range for both images to be between 0 and 1000.
Show/hide images with the eye button ( <img src="../fig/eye_icon.png" alt="eye icon" height="24" class="figure"> ), or by double clicking on the image name
in the overlay list.</p>
<ul>
<li><em>Do they have the same orientation?</em></li>
<li><em>Which brain characteristics are more visible in the T1w and
which are more visible on FLAIR?</em></li>
</ul>
</div>
</div>
</div>
<div id="accordionHint1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button hint-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseHint1" aria-expanded="false" aria-controls="collapseHint1">
  <h4 class="accordion-header" id="headingHint1"> Give me a hint </h4>
</button>
<div id="collapseHint1" class="accordion-collapse collapse" data-bs-parent="#accordionHint1" aria-labelledby="headingHint1">
<div class="accordion-body">
<ul>
<li>Use <code>fslhd</code> to get information on dimension and voxel
size.</li>
<li>Look at the location panel to help with information about
orientation</li>
</ul>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<p><em>Do the T1 and the FLAIR have the same dimension?</em></p>
<p><strong>No</strong>-Using <code>fslhd</code>, we can see that the
dimensions (<code>dim1</code>, <code>dim2</code>, and <code>dim3</code>)
of the T1 are 176 x 240 x 161 and the dimensions of the FLAIR image are
256 x 256 x 35.</p>
<p><em>Do the T1 and the FLAIR have the same resolution?</em></p>
<p><strong>No</strong>-From the same <code>fslhd</code> commands, the
resolution can be found in the fields <code>pixdim1</code>,
<code>pixdim2</code>, and <code>pixdim3</code>. For the T1 the
resolution is 1.20 x 1.05 x 1.05 mm. For the FLAIR it is 0.859 x 0.859 x
5.00mm</p>
<p><em>Do the T1 and the FLAIR have the same orientation?</em></p>
<p><strong>No</strong> In the bottom right panel you should see the
warning: “Images have different orientations/fields of view”</p>
<p><em>What brain characteristics are more visible in the T1w and which
are more visible on FLAIR?</em></p>
<p>On T1w, grey and white matter are more easily distinguishable. On
FLAIR, brain lesions – white matter hyperintensities – are more clearly
visible</p>
</div>
</div>
</div>
</div>
<p>In the <a href="structural-mri.html">next episode on structural
MRI</a>, we will learn how to align (register) the two images together
to be able to look at the same point in the brain in both images.</p>
</div>
</section><section><h2 class="section-heading" id="additional-material">Additional material<a class="anchor" aria-label="anchor" href="#additional-material"></a>
<a class="anchor" aria-label="anchor" href="#additional-material"></a>
</h2>
<hr class="half-width">
<p>For a more extensive tutorial on FSLeyes features, please refer to
the <a href="https://open.win.ox.ac.uk/pages/fslcourse/practicals/intro1/index.html" class="external-link">FSL
course - FSLeyes practical</a></p>
<p>FSLeyes manual: <a href="https://open.win.ox.ac.uk/pages/fsl/fsleyes/fsleyes/userdoc/index.html" class="external-link uri">https://open.win.ox.ac.uk/pages/fsl/fsleyes/fsleyes/userdoc/index.html</a></p>
</section><section><h2 class="section-heading" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<hr class="half-width">
<ul>
<li>FSL course material: <a href="https://open.win.ox.ac.uk/pages/fslcourse/website/online_materials.html" class="external-link uri">https://open.win.ox.ac.uk/pages/fslcourse/website/online_materials.html</a>
</li>
<li>McCarthy, Paul. (2021). FSLeyes (1.2.0). Zenodo. <a href="https://doi.org/10.5281/zenodo.5504114" class="external-link uri">https://doi.org/10.5281/zenodo.5504114</a>
</li>
<li>Michael Joseph, Jerrold Jeyachandra, and Erin Dickie (eds): “Data
Carpentry: Introduction to MRI Data Analysis.” Version 2019.11, November
2019, <a href="https://carpentries-incubator.github.io/SDC-BIDS-IntroMRI/open-mri-datasets/index.html" class="external-link">https://github.com/carpentries-incubator/SDC-BIDS-IntroMRI</a>
</li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Images are sheets or cubes of numbers.</li>
<li>Medical image data is typically stored in DICOM or Nifti format.
They include a header that contains information on the patient and/or
the image characteristics.</li>
<li>An affine transformation maps the voxel location to real-world
coordinates.</li>
<li>Medical image viewers allow to navigate an image, adjust contrast,
and localise brain regions with respect to an atlas.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-structural-mri"><p>Content from <a href="structural-mri.html">Structural MRI: Bias Correction, Segmentation and Image Registration</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/structural-mri.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 65 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I process and quantify structural MRI scans?</li>
<li>How do I register MRI with other modalities?</li>
<li>How do I get key metrics out?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Perform basic pre-processing steps, such as bias correction and
tissue segmentation</li>
<li>Assess some common imaging artefacts in the sturctura MRI</li>
<li>Discover how to align and quantify neuroimaging data at regional
level</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>In this section, you will be learning how to process and quantify
structural MRI scans. T1-weighted structural MRI scans are the
“workhorse” scan of dementia research. They provide high-resolution,
detailed pictures of a patient’s anatomy, allowing researchers to
visualize where atrophy caused by Alzheimer’s disease or other dementias
is occurring. In addition, it provides anatomical reference to other
imaging modalities, such as functional MRI and positron emission
tomography (PET), that provide lower-resolution maps of brain function
and pathology, so that regional quantification of key areas can be
assessed in these scans.</p>
<p>We will be using two widely used software packages: <a href="https://www.fil.ion.ucl.ac.uk/spm/" class="external-link">SPM</a> and <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki" class="external-link">FSL</a>. These packages
provide analysis and visualization functionality of structural and
functional neuroimaging data, and they can be used in both
cross-sectional and longitudinal studies. The subsequent outputs from
these pipelines can be used in the quantification of other imaging
modalities.</p>
<p>After the course, you will be able to perform basic measurements
relevant to dementia research from structural MRI brain scans.</p>
<p>We will use the SPM and FSL tools to perform:</p>
<ul>
<li>image visualization of analysis outputs,</li>
<li>intensity inhomogeneity correction,</li>
<li>structural MRI segmentation,</li>
<li>quantification of volumetric outputs, and</li>
<li>registration to a standard space atlas.</li>
</ul></section><section><h2 class="section-heading" id="opening-up-an-image">Opening up an image<a class="anchor" aria-label="anchor" href="#opening-up-an-image"></a>
<a class="anchor" aria-label="anchor" href="#opening-up-an-image"></a>
</h2>
<hr class="half-width">
<p>We are going to be working in the <code>StructuralMRI</code>
subfolder under <code>data</code> in your home directory.From the
previous lesson, you learned how to view and navigate images.</p>
<p>Clicking on the Applications in the upper left-hand corner and select
the terminal icon. This will open a terminal window that you will use to
type commands <img src="../fig/aic_smri_launch_terminal.png" alt="Launch the terminal" class="figure"></p>
<p>From the terminal window, type <code>fsleyes</code> to open up the
image and have a look around. <img src="../fig/aic_smri_fsleyes.png" alt="Open FSLeyes" class="figure"></p>
<p>Now we choose the file <code>sub-OAS_30003_T1w.nii</code> by going to
the File menu and choosing the Add Image command <img src="../fig/aic_smri_fsleyes_addfile.png" alt="Add file" class="figure"><img src="../fig/aic_smri_fsleyes_choosefile.png" alt="Choose File" class="figure"></p>
<div id="exercise-1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1<a class="anchor" aria-label="anchor" href="#exercise-1"></a>
</h3>
<div class="callout-content">
<p>Close fsleyes and then re-open the viewer. This time use the other
image in the folder <code>sub-OAS30217_T1w.nii</code>.</p>
<p><em>What differences do you notice?</em></p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="run-bias-correction-and-tissue-segmentation">Run Bias Correction and Tissue Segmentation<a class="anchor" aria-label="anchor" href="#run-bias-correction-and-tissue-segmentation"></a>
<a class="anchor" aria-label="anchor" href="#run-bias-correction-and-tissue-segmentation"></a>
</h2>
<hr class="half-width">
<p>Small variations in the magnetic field can result in changes in the
image intensity that vary slowly spatially. These variations are not due
to anatomical differences. We can visually identify this <em>image
inhomogeneity</em> in the white matter, where voxels in one part of the
brain might be so affected by it that they have similar intensity values
as grey matter voxels in other brain regions. However, the intensities
in the white matter voxels should be more or less uniform throughout the
brain. Any remaining inhomogeneity in the image can significantly
influence the results of automated image processing techniques, so we
need to correct for these effects. The process that removes this image
inhomogeneity is typically referred to as <em>bias correction</em>.</p>
<p>The next step is to reliably identify what type of tissue each voxel
contains. While the resolution of structural MRI is quite high
(typically around 1 mm), there is still the likelihood that a voxel will
contain more than one tissue in it. The process of <em>tissue
segmentation</em> looks at the voxel intensity, compares it to its
neighbours and prior information about what tissues we would expect to
have in that voxel and assigns a probability that the voxel contains
that tissue. It typically generates <em>n</em> different volumes, where
<em>n</em> is the number of tissue types you want to use to classify the
brain. We typically focus on three tissue probability maps in
particular:</p>
<ul>
<li>Grey matter (GM),</li>
<li>White matter (WM), and</li>
<li>Cerebrospinal fluid (CSF)</li>
</ul>
<p>SPM performs the <em>bias correction</em> and <em>tissue
segmentation</em> steps simultaneously. Follow the steps below to obtain
bias-corrected images and tissue probability maps.</p>
<div class="section level3">
<h3 id="bias-correction-and-segmenation-steps">Bias Correction and Segmenation Steps<a class="anchor" aria-label="anchor" href="#bias-correction-and-segmenation-steps"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Type <code>spm pet</code> to launch SPM <img src="../fig/aic_smri_terminal_window.png" alt="Launch SPM" class="figure">
</li>
<li>SPM will then create a number of windows. You want to look at the
Main Menu Window that has all of the buttons. <img src="../fig/aic_smri_spm.png" alt="SPM windows" class="figure">
</li>
<li>From main menu, select the Segment button. This will launch a window
known as the <em>batch editor</em>, where you can adjust settings on the
pipeline to be run. <img src="../fig/aic_smri_seg_batch.png" alt="SPM Batch editor" class="figure">
</li>
<li>Edit the options for segmentation:
<ol style="list-style-type: lower-alpha">
<li>Under Data-&gt;Channels-&gt;Volume, click on “Specify…”. <img src="../fig/aic_smri_seg_volumes.png" alt="Specify volumes" class="figure">
</li>
<li>In the dialog box that opens up, please navigate to the folder
<code>data</code> and then <code>StructuralMRI</code>. Then select the
first image <code>sub-OAS30003_T1w.nii</code>. Once you click on it, you
will notice the file move down to the bottom of the box which represents
the list of selected files. <img src="../fig/aic_smri_seg_chooset1.png" alt="Choose T1 image" class="figure">
</li>
<li>Click the <code>Done</code> button</li>
<li>Back in the batch editor, under Data-&gt;Save Bias Corrected, please
choose “Save Field and Corrected” <img src="../fig/aic_smri_seg_bcoption.png" alt="Choose bias correction option" class="figure">
</li>
<li>Under the Tissues section, please make sure that the first three
tissue types, which represent GM, WM, and CSF, have the native tissue
subfield set to native, while the final three tissue types (4-6), which
represent non-brain structures, have the native tissue subfield set to
None. <img src="../fig/aic_smri_seg_native.png" alt="Native segmentation" class="figure">
</li>
</ol>
</li>
<li>Click the green run button to start! It should take about 5-10
minutes. You will see a lot of other things happening in other windows.
The terminal will say <code>Done - Segment</code> when it has
finished.</li>
</ol>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> Reproducing your work </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" aria-labelledby="headingSpoiler1" data-bs-parent="#accordionSpoiler1">
<div class="accordion-body">
<p>When you are using these workflows for your actual research, we
<strong>highly recommend</strong> that you save the SPM pipelines so
that you could run them again on the exact same data with the exact same
settings. You can do that by selecting <code>Save batch</code> from the
<code>File</code> menu. This will save the batch, or pipeline, as a file
with a <code>.mat</code> extension. You can load this file back in by
selecting the <code>Load batch</code> from the <code>File</code> menu
and selecting the file you save.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="quality-check">Quality check<a class="anchor" aria-label="anchor" href="#quality-check"></a>
<a class="anchor" aria-label="anchor" href="#quality-check"></a>
</h2>
<hr class="half-width">
<p>The quality check is an important part of any analysis. We are going
to visualize the outputs from SPM Segment and make sure that the bias
correction and segmentation have worked.</p>
<div class="section level3">
<h3 id="bias-correction">Bias correction<a class="anchor" aria-label="anchor" href="#bias-correction"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Use <code>fsleyes</code> again and open up the original image
<code>sub-OAS30003_T1w.nii</code> as you did at the start of the
session.</li>
<li>Change the image lookup table to <code>NIH [Brain colors]</code>
<img src="../fig/aic_smri_fsleyes_selectnih.png" alt="FSL eyes with NIH colormap" class="figure">
</li>
<li>Then change the image minimum to 40 and the maximum to 600. This
means that all intensities 40 and below will map to the first color in
the lookup table, and all voxels 600 and above will map to the last
color. The white matter should be yellow to red. <img src="../fig/aic_smri_fsleyes_minmax.png" alt="Change min and max intensity" class="figure"><br>
</li>
<li>Next add the bias corrected image, which is called
<code>msub-OAS30003_T1w.nii</code>. Change the lookup table to NIH as
you did in Step 2. Change the minimum to 40 and maximum intensity to 500
similar to what you did in Step 2 and 3. <img src="../fig/aic_smri_fsleyes_biasnih.png" alt="Bias in image using NIH map" class="figure">
</li>
</ol>
<p>When you add this image, it will overlay on top of the original
image. Think of this new image a completely opaque, so that you no
longer see the original one. If you want to see the original one, then
you need to either turn it off using the eye icon ( <img src="../fig/eye_icon.png" alt="eye icon" height="24" class="figure"> ) right by the
file, or you need to turn the opacity (slider near the top of the screen
which is marked opacity.)</p>
<div id="exercise-2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="exercise-2" class="callout-inner">
<h3 class="callout-title">Exercise 2<a class="anchor" aria-label="anchor" href="#exercise-2"></a>
</h3>
<div class="callout-content">
<p>Use the eye icon in the overlay list right next to the file
<code>msub-OAS30003_T1w.nii</code> and turn this image off and on many
times. This will allow you to compare with the original image.</p>
<p><em>What do you notice about the image in the white matter area when
comparing the bias correct and original image?</em></p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="tissue-segmentation">Tissue segmentation<a class="anchor" aria-label="anchor" href="#tissue-segmentation"></a>
</h3>
<p>Now that we are happy with the bias correction, lets look at the
tissue segmentation.</p>
<ol style="list-style-type: decimal">
<li>Use the icon to turn off the original image. Select the bias
corrected image and make sure the colormap is back to the first option
“Greyscale” <img src="../fig/aic_smri_fsleyes_orig.png" alt="Bias correted image in greyscale" class="figure">
</li>
<li>Now add the grey matter probability image
<code>c1sub-OAS30003_T1w.nii</code>.</li>
<li>Choose the probability map and set the lookup table to Red. Change
the minimum intensity to 0.2 and the maximum intensity to 0.9. This will
eliminate some noise from very low probability voxels.</li>
<li>Use the opacity slider to make the grey matter probability map
transparent. <img src="../fig/aic_smri_fsleyes_gm.png" alt="Looking at grey matter image" class="figure">
</li>
<li>Look around the image, zoom in places, and try turning the grey
matter probability map off and on. The goal is to make sure the grey
matter probability map is not:
<ol style="list-style-type: lower-alpha">
<li>Missing any grey matter</li>
<li>Not including other tissue (WM, CSF, non-brain tissue that has a
similar intensity to GM)</li>
</ol>
</li>
</ol>
<div id="exercise-3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-3" class="callout-inner">
<h3 class="callout-title">Exercise 3<a class="anchor" aria-label="anchor" href="#exercise-3"></a>
</h3>
<div class="callout-content">
<p>Now do the same steps with the white matter image
<code>c2sub-OAS30003_T1w.nii</code> and the cerebrospinal fluid image
<code>c3sub-OAS30003_T1w.nii</code>. Choose different color
colormaps.</p>
<p><em>Do these images look like they have identified the white matter
and CSF in the T1 weighted image correctly?</em></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>You should have an output that looks something like this. <img src="../fig/aic_smri_tissue_seg_check.png" alt="Tissue segmentation check" class="figure"></p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="obtaining-volume">Obtaining volume<a class="anchor" aria-label="anchor" href="#obtaining-volume"></a>
<a class="anchor" aria-label="anchor" href="#obtaining-volume"></a>
</h2>
<hr class="half-width">
<p>One thing that we are often interested in is to obtain the actual
volume of grey matter, or a particular brain region. There are helpful
utilities in FSL to extract the volume from the tissue probability maps.
First we will change our working directory to the Structural MRI
folder:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/StructuralMRI</span></code></pre>
</div>
<p>Then we will run this command to get the total grey matter
volume:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-V</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>719954 961026.312500</code></pre>
</div>
<p>This will produce two numbers. The first number is the number of
voxels in the grey matter. These voxels as discussed earlier have
physical dimensions indicating how the volume that each individual voxel
represents. So the second value indicates the total volume of the grey
matter (usually represented in units of cubic millimeters, 1<span class="math inline">\(ml\)</span> = 1000<span class="math inline">\(mm^3\)</span>).</p>
</section><section><h2 class="section-heading" id="coregistration-to-standard-space">Coregistration to standard space<a class="anchor" aria-label="anchor" href="#coregistration-to-standard-space"></a>
<a class="anchor" aria-label="anchor" href="#coregistration-to-standard-space"></a>
</h2>
<hr class="half-width">
<p>MRI scans can be acquired in any orientation. Even when we think we
are getting a sagittal or coronal acquisition, the patient may end up in
the scanner at a slant. This makes it difficult to identify key
anatomical landmarks. We may also want to compare common anatomical
structures across a whole sample of subjects. The main solution to this
is to use <em>image registration</em> to orient our images and align
them with a standard anatomical coordinate system. In this case, we will
be aligning our data to the Montreal Neurological Institute <a href="https://mcin.ca/research/neuroimaging-methods/atlases/" class="external-link">MNI152
atlas</a>. We are not looking to perform an exact voxel to voxel match
between our image and the atlas. Instead, we just want to align the
images such that the orientation and the relative size are aligned.</p>
<div class="section level3">
<h3 id="skull-stripping">Skull stripping<a class="anchor" aria-label="anchor" href="#skull-stripping"></a>
</h3>
<p>Before we can perform the registration, we will use the tissue
probability maps to <em>skull strip</em> the image. Skull stripping
removes the non-brain tissue (scalp, dura, neck, eyes, etc) from the
image. Before we run the commands, let’s first check what working
directory we are in by using the command <code>pwd</code>:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="bu">pwd</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>/home/as2-streaming-user/data/StructuralMRI</code></pre>
</div>
<p>If you have a different output from the above, then run the following
command:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/StructuralMRI</span></code></pre>
</div>
<p>First we will use the FSL utility <code>fslmaths</code> to create a
brain mask by using the tissue probability maps from SPM.
<code>fslmaths</code> is a great swiss-army knife utility to do lots of
helpful little image processing bits.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">fslmaths</span> c1sub-OAS30003_T1w.nii <span class="at">-add</span> c2sub-OAS30003_T1w.nii <span class="at">-add</span> c3sub-OAS30003_T1w.nii <span class="at">-thr</span> 0.5 <span class="at">-bin</span> sub-OAS30003_T1w_brain_mask.nii</span></code></pre>
</div>
<p>Let’s break this command down a little bit:</p>
<ul>
<li>First, we state the command we want to run
<code>fslmaths</code>
</li>
<li>We then specify our input image, the GM map
<code>c1sub-OAS30003_T1w.nii</code>
</li>
<li>We then specify the first operation <code>-add</code>
</li>
<li>We then specify what we want to add to our input image. In this
case, it is the WM map <code>c2sub-OAS30003_T1w.nii</code>. The
resulting image would contain the probability that a voxel is either GM
or WM.</li>
<li>We then specify that we want to add another image, and this time it
is the CSF map. This image now holds the probability that a voxel is GM,
WM, or CSF, which are the three main tissue types in the brain that we
want to process.</li>
<li>We will then threshold this image at 0.5 using the
<code>-thr 0.5</code> option. This says to only keep voxels who have a
probability of 0.5 or greater. All other voxels are set to 0.</li>
<li>Our final operation is to <em>binarize</em> the image. Any values
that are not zero are set to one. This creates a mask which says whether
the voxel is inside (<strong>1</strong>) or outside (<strong>0</strong>)
of the brain.<br>
</li>
<li>Finally, we save our results into the new image file
<code>sub-OAS30003_T1w_brain_mask.nii</code>
</li>
</ul>
<p>Now that we have created a mask, we are going to remove all the
information outside of the mask using the following command:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="ex">fslmaths</span> msub-OAS30003_T1w.nii <span class="at">-mas</span> sub-OAS30003_T1w_brain_mask.nii.gz msub-OAS30003_T1w_brain.nii</span></code></pre>
</div>
<p>This command masks our bias corrected image with the brain mask and
makes a new file which has the name
<code>msub-OAS30003_T1w_brain.nii</code>. Take a look at the image in
<code>fsleyes</code>. <img src="../fig/aic_smri_fsleyes_skullstripped.png" alt="Skull stripped image" class="figure"></p>
<p>We will then use the FSL registration program <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT" class="external-link">FLIRT</a> to align
our image to the standard space MNI152. Please follow the steps
below:</p>
<ol style="list-style-type: decimal">
<li>On the terminal window, please type in the following command
<code>Flirt</code>
</li>
<li>This will open a dialog box. We will change the following settings:
<ol style="list-style-type: lower-alpha">
<li>For reference image, click on the folder icon and choose the image
<code>MNI152_T1_1mm_brain</code>
</li>
<li>For the input image, please select the mask we created above
<code>msub-OAS30003_T1w_brain.nii</code>
</li>
<li>For the output image, please type in a new name
<code>msub-OAS30003_T1w_brain_MNI.nii</code> The final command setup
should look like the screenshot below. <img src="../fig/aic_smri_flirt.png" alt="FLIRT window" class="figure">
</li>
</ol>
</li>
</ol>
<p>If your window looks like this, then click the <strong>Go</strong>
button at the bottom, in the terminal, you will see the <em>command
line</em> program that would run what you have set up in the dialog box.
If you were to select that command and run it in the terminal it would
do the same thing.</p>
</div>
<div class="section level3">
<h3 id="quality-check-1">Quality check<a class="anchor" aria-label="anchor" href="#quality-check-1"></a>
</h3>
<p>Let’s open <code>fsleyes</code> and open the output from the
co-registration <code>msub-OAS30003_T1w_brain_MNI.nii</code>. <img src="../fig/aic_smri_fsleyes_mnispace.png" alt="T1w in MNI space" class="figure"></p>
<p>Now click on the Add Standard function. This is where fsleyes keeps
all of the standard atlases and templates so that you can quickly access
them. <img src="../fig/aic_smri_fsleyes_addstd.png" alt="Add standard function" class="figure"></p>
<p>Select the <code>MNI152_T1_1mm_brain</code> from this list of files.
<img src="../fig/aic_smri_fsleyes_choosemni.png" alt="Choose MNI image" class="figure"></p>
<p>We can now check if our image is registered by flicking back and
forth between the MNI image and our image.</p>
</div>
</section><section><h2 class="section-heading" id="stretch-exercises">Stretch exercises<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
</h2>
<hr class="half-width">
<p>If you have completed all of the above and want to keep working on
more structural imaging data, please try the exercises below.</p>
<div id="bonus-exercise-1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="bonus-exercise-1" class="callout-inner">
<h3 class="callout-title">BONUS Exercise 1<a class="anchor" aria-label="anchor" href="#bonus-exercise-1"></a>
</h3>
<div class="callout-content">
<p>Extract the volumes from the WM and CSF probability maps for
<code>sub-OAS30003_T1w.nii</code>.</p>
<p><em>What are the three tissue volumes?</em></p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># This is the same command as above to get the GM volume out</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-V</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># Now for the WM volume</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-V</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co"># Finally, for the CSF volume</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-V</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>719954 961026.312500
462937 617948.687500
599177 799807.750000</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="bonus-exercise-2" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="bonus-exercise-2" class="callout-inner">
<h3 class="callout-title">BONUS Exercise 2<a class="anchor" aria-label="anchor" href="#bonus-exercise-2"></a>
</h3>
<div class="callout-content">
<p>The volumes that come out of <code>fslstats</code> assume that each
voxel is completely full of GM, even though for some voxels the
probability may be very small. That can lead to inaccuracies, so there
are a couple of ways we can more accurately measure from tissue
probability maps.</p>
<p>Before we start, let’s make sure we are in the right working
directory by using the <code>cd</code> command.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/StructuralMRI</span></code></pre>
</div>
<p>The first approach is to only count voxels with a
<strong>majority</strong> of GM. So we will threshold by the value of
0.5 before calculating our volume.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-l</span> 0.5 <span class="at">-V</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>465968 621994.569978</code></pre>
</div>
<p>The second approach is to get the mean and volume of the all the
non-zero voxels.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="ex">fslstats</span> c1sub-OAS30003_T1w.nii <span class="at">-M</span> <span class="at">-V</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>0.641076 719954 961026.312500</code></pre>
</div>
<p>This will produce three numbers:</p>
<ol style="list-style-type: decimal">
<li>The mean of the non-zero voxels</li>
<li>The number of voxels greater than zero.</li>
<li>The volume of the voxels greater than zero.</li>
</ol>
<p>If you multiply (1) by (3), this would be what we call the
<em>probabilistic</em> volume of the GM and it accurately accounts the
amount of GM in each voxel, which should give you a volume of around
616,090.</p>
<p><em>How do these volumes compare with the original volume you
obtained?</em></p>
</div>
</div>
</div>
<div id="bonus-exercise-3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="bonus-exercise-3" class="callout-inner">
<h3 class="callout-title">BONUS Exercise 3<a class="anchor" aria-label="anchor" href="#bonus-exercise-3"></a>
</h3>
<div class="callout-content">
<p>Let’s take a look at our other image
<code>sub-OAS30217_T1w.nii</code>. Perform the same steps as you did for
the first image:</p>
<ul>
<li>Segmentation</li>
<li>Skull Stripping</li>
<li>Co-registration to standard space Run the same skull stripping and
registration as you have done before. Now open up both standard space
images in <code>fsleyes</code>
</li>
</ul>
<p><em>What do you observe about the images?</em></p>
</div>
</div>
</div>
<div id="bonus-exercise-4" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="bonus-exercise-4" class="callout-inner">
<h3 class="callout-title">BONUS Exercise 4<a class="anchor" aria-label="anchor" href="#bonus-exercise-4"></a>
</h3>
<div class="callout-content">
<p>Let’s now try to co-register two imaging modalities from one
participant (<em>within-subject registration</em>)</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="bu">cd</span> ~/data/ExtraStructuralMRI</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="fu">ls</span></span></code></pre>
</div>
<p>At the end of the previous session on data visualization, you looked
at a T1-weighted scan and a FLAIR scan from the same participant
(<code>sub-OAS30003_T1w.nii.gz</code> and
<code>sub-OAS30003_FLAIR.nii.gz</code>, load them again in FSLeyes if
you need a refresh). As you will have noticed, they have different
dimensions, resolution and orientation, so if we want to look at the
same point in the brain in both images we need to align them.</p>
<p>First, we need to choose which image we want to keep unchanged
(<em>reference</em>) and which one we want to align to the reference
(<em>input</em>). Let’s assume we want to register the FLAIR image to
the T1. We have already prepared a skull-stripped version of the images
for you so they are ready to be aligned with <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT" class="external-link">FLIRT</a>.</p>
<p>The way to do this is very similar to what you did before to
co-register a T1 to standard space. Please follow the steps below:</p>
<ol style="list-style-type: decimal">
<li>On the terminal window, type <code>Flirt</code>
</li>
<li>This will open the dialog box you used before. The new settings are:
<ol style="list-style-type: lower-alpha">
<li>For reference image, delete the text in the box and type
<code>~/data/ExtraStructuralMRI</code>, then click on the folder icon
and choose the image <code>sub-OAS30003_T1w_brain.nii.gz</code>
</li>
<li>Change the Model/DOF (input to ref) to
<code>Rigid Body (6 parameter model)</code>
</li>
<li>For the input image, click on the folder icon and choose the image
<code>sub-OAS30003_FLAIR_brain.nii.gz</code>
</li>
<li>For the output image, please type in a new name
<code>sub-OAS30003_FLAIR_to_T1w.nii.gz</code>
</li>
</ol>
</li>
</ol>
<p>The final command setup should look like the screenshot below: <img src="../fig/aic_smri_flirt_T1FLAIR.png" alt="Coregistration of T1 and FLAIR" class="figure"></p>
<p>If your window looks like this, then click the <strong>Go</strong>
button at the bottom, in the terminal, you will see the <em>command
line</em> program that would run what you have set up in the dialog box.
If you were to select that command and run it in the terminal it would
do the same thing.</p>
<p>Once done, open the result in FSLeyes:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">fsleyes</span> sub-OAS30003_T1w_brain.nii.gz sub-OAS30003_FLAIR_to_T1w.nii.gz <span class="kw">&amp;</span></span></code></pre>
</div>
<p>We can now check if our image is registered by flicking back and
forth between the T1 image and the FLAIR registered image.</p>
<p><em>Can you think of why the registered FLAIR image appears blurred
in the sagittal and coronal plane?</em></p>
<p>Now try to do the opposite: co-register the T1 to the FLAIR.</p>
<p><em>What differences do you notice with respect to the previous case
(FLAIR co-registered to T1)?</em></p>
<p><em>Can you think of different cases where you would want to use T1
or FLAIR as your reference?</em></p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Structural MRI provides high-resolution anatomic information for
neuroimaging analysis</li>
<li>Bias correction removes image inhomogeneities</li>
<li>Tissue segmentation identifies key tissue types (grey matter, white
matter, cerebrospinal fluid) from T1 weighted images</li>
<li>Co-registration of MRI to other modalities can be used to analyse
these images at a regional level.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-pet-imaging"><p>Content from <a href="pet-imaging.html">Processing and analysing PET brain images</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/pet-imaging.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 45 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What does positron emission tomography measure?</li>
<li>What are some common processing steps used for PET
quantification?</li>
<li>How can I extract key measurements of tracer binding from dynamic
PET data?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the basic structure of 4D PET data and key variables
needed for quantification.</li>
<li>Explain the differences between static and dynamic acquisitions, and
what information can be derived from them.</li>
<li>Perform the basic processing steps involved in PET image
quantification and analysis.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>This tutorial is an introduction to working with PET data in the
context of AD neuroimaging. Due to the limited time, we will not have
time to fully recreate a typical image processing pipeline for PET data,
but have included enough steps that you’ll be able to perform the
minimum steps needed to generate a parametric SUVR image. The provided
dataset includes T1-weighted MRI, [18F]MK-6240 tau PET and [11C]PiB
amyloid PET scans for a single subject at a single timepoint. For ease,
the T1-weighted image was already rigidly aligned and resliced to a 1mm
isotropic image in MNI152 space. The provided PET scans were acquired
using different protocols to demonstrate two common ways that PET data
can be acquired. The tutorial will explain the differences between these
types of acquisitions and what information can be derived from them.</p>
<div class="section level3">
<h3 id="background-pet-data-image-processing-and-quantification">Background: PET data, image processing, and quantification<a class="anchor" aria-label="anchor" href="#background-pet-data-image-processing-and-quantification"></a>
</h3>
<p>PET data are collected on the scanner typically in <em>list
mode</em>. This is quite literally a logged record of every event the
scanner detects, but this type of data is not all that useful for
interpretation. Viewing the images requires that the list mode data be
reconstructed. The provided images have already been reconstructed with
the widely-used Ordered Subset Expectation Maximization (OSEM) algorithm
with common corrections (scatter, dead time, decay, etc.) already
applied during the reconstruction. Notably, no smoothing was applied
during the PET reconstruction.</p>
</div>
</section><section><h2 class="section-heading" id="gaining-familiarity-with-4d-pet-data">Gaining familiarity with 4D PET data<a class="anchor" aria-label="anchor" href="#gaining-familiarity-with-4d-pet-data"></a>
<a class="anchor" aria-label="anchor" href="#gaining-familiarity-with-4d-pet-data"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="prepare-working-directory">Prepare working directory<a class="anchor" aria-label="anchor" href="#prepare-working-directory"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Open a new terminal window and navigate to the directory with the
unprocessed PET NIfTI images and data
<code>/home/as2-streaming-user/data/PET_Imaging</code>.</li>
<li>Use <code>ls</code> to view the contents of this directory</li>
<li>Use <code>cd</code> to change your working directory to the
following location:</li>
</ol>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">cd</span> /home/as2-streaming-user/data/PET_Imaging/UnprocessedData</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="view-pet-metadata">View PET metadata<a class="anchor" aria-label="anchor" href="#view-pet-metadata"></a>
</h3>
<p>View the information in the .json file for MK-6240 and PiB images by
opening the .json files for the MK-6240 and PiB images. For example,
type the following into the terminal:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">gedit</span> sub001_pib.json</span></code></pre>
</div>
<div id="accordionHint1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button hint-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseHint1" aria-expanded="false" aria-controls="collapseHint1">
  <h4 class="accordion-header" id="headingHint1"> Give me a hint </h4>
</button>
<div id="collapseHint1" class="accordion-collapse collapse" data-bs-parent="#accordionHint1" aria-labelledby="headingHint1">
<div class="accordion-body">
<p>Open up multiple terminal windows to view the .json file contents
side-by-side.</p>
</div>
</div>
</div>
</div>
<ul>
<li><p>Note that the Time section differs with regard to the scant start
and injection start times. Namely, the MK-6240 scan starts 70 minutes
after tracer injection, whereas the PiB image starts at the same time as
the tracer injection. The latter acuisition protocol is often referred
to as a <em>full dynamic</em> acquisition and enables us to calculate
more accurate measurements like distribution volume ratio (DVR) and
often additional parameters from the time-series data (e.g., <span class="math inline">\(R_1\)</span> relative perfusion). If we had
arterial data available, we could also use the full dynamic scan to
perform kinetic modeling.</p></li>
<li><p>Also note the framing sequences differs between the two tracers.
MK-6240 is using consecutive 5-minute frames whereas PiB starts with
2-minute frames for the first 10 minutes and then 5-minute frames
thereafter.</p></li>
<li>
<p>For both images, the decay correction factors correspond to the
scan start time (indicated by “START” in the DecayCorrected field). This
may or may not have consequences for how we quantify the image. For
example, if we wanted to calculate the standard uptake value <span class="math inline">\(SUV = C(t) / InjectedDose * BodyMass\)</span>,</p>
<p>we would need to decay correct the MK-6240 scan data to tracer
injection but this is not needed to calculate SUV for the PiB scan
because the scan started with tracer injection.</p>
</li>
</ul>
<p>Now close the .json files in <code>gedit</code>.</p>
</div>
<div class="section level3">
<h3 id="view-4d-pet-data">View 4D PET data<a class="anchor" aria-label="anchor" href="#view-4d-pet-data"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Open <code>sub001_pib.nii</code> using <code>fsleyes</code>.</li>
<li>Set the minimum threshold to 0 and the maximum threshold to 30,000
Bq/mL</li>
<li>You are currently viewing individual PET frames that have not been
denoised in any way. Notice the high noise level in the individual PET
frames. This is why we often apply some type of denoising algorithm to
the PET data before processing and quantification.</li>
<li>Use your cursor to scroll around the image and observe the values in
voxels in the brain. These values are activity concentrations given in
<span class="math inline">\(Bq/mL\)</span>, where Bq (Becquerel) is the
SI unit for radioactivity and is expressed as a rate (counts per
second). In PET, the noise in the image is proportional to the inverse
of the square root of the counts. Thus, the more counts detected, the
less noisy the image will appear.</li>
<li>Use the Volume field to advance through the PET frames from the
first frame (index = 0) to the last frame (index = 16). Moving higher in
volume indices is moving forward in time, like a 3D movie, as the tracer
distributes throughout the brain over time. Note how the distribution of
the tracer changes from the first frame to the last frame. The tracer
distribution in early frames of this acquisition largely reflects the
tracer perfusing the brain tissue whereas later frames largely reflect a
combination of free tracer and specific and non-specific tracer binding.
You may need to adjust the upper window level to a lower value to more
clearly visualize the later PET frames. You’ll also likely notice that
the later frames are noisier than the beginning frames, again, this has
to do with counting statistics and the reduced counts detected over time
due to radioactive decay and lower tracer concentration in the brain at
later timepoints.</li>
<li>Close the 4D PET image in FSL by selecting the image in the Overlay
list at the bottom of the page and clicking Overlay -&gt; Remove from
the menu at the top of the page.</li>
</ol>
</div>
</section><section><h2 class="section-heading" id="creating-a-sum-pet-image">Creating a SUM PET image<a class="anchor" aria-label="anchor" href="#creating-a-sum-pet-image"></a>
<a class="anchor" aria-label="anchor" href="#creating-a-sum-pet-image"></a>
</h2>
<hr class="half-width">
<p>We’ll create two different SUM images from the PiB scan; one for
early- and one for late-frame data to visualize the differences in
tracer distribution between these timepoints more easily. The early
frame data will SUM 0-20 minutes post-injection whereas the late frame
will SUM 50-70 minutes post-injection. We’ll do the late-frame image
first and then the early-frame image. You can reference the
FrameTimeStart and FrameTimeEnd fields in the .json file to determine
which frames correspond to 0-20 min and 50-70 min postinjection.</p>
<div class="section level3">
<h3 id="using-imcalc-to-sum-frames">Using ImCalc to Sum Frames<a class="anchor" aria-label="anchor" href="#using-imcalc-to-sum-frames"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Open SPM12 by typing <code>spm pet</code> in the command
line.</p></li>
<li><p>Select the <code>ImCalc</code> module. <img src="../fig/aic_pet_imcalc_start.png" alt="SPM ImCalc module" class="figure"></p></li>
<li>
<p>For each variable in the GUI, you will need to specify values
using the <code>Specify</code> button. Use the values specified below
for each variable listed.</p>
<ul>
<li><p><code>Input Images</code> – here we want to specify the input
images that we are going to use to perform the image calculation. The
order that the images are specified will determine the order they are
referred to in the expression field below (e.g., the first image is i1,
the second image is i2, etc.,) However, SPM will only load one frame at
a time for 4D data, so each frame needs to be specified individually
using the Frames field. The frame number is then delineated by the
filename followed by a comma and the frame number. Note that SPM uses
index 1 for the first frame, which corresponds to index 0 in
FSL.</p></li>
<li><p>Enter the frame number corresponding to the frame that spans
50-55 min post-injection (frame number 14) and hit enter. Click on the
<code>sub001_pib.nii,14</code> file to add this to the list. <img src="../fig/aic_pet_imcalc_choose14.png" alt="Choose Frame 14" class="figure"></p></li>
<li><p>Enter the next framenumber and similarly add it to the list.
Repeat until you’ve added the last four frames of the PiB image
corresponding to 50-70 min post-injection (frames 14, 15, 16, and 17).
Note the order you input the images corresponds to i1, i2, … in the
Expression field later. Once you’ve selected the last four frames click
Done to finalize the selection. <img src="../fig/aic_pet_imcalc_chosenall.png" alt="Choose all" class="figure"></p></li>
<li><p><code>Output Filename</code> – enter text
<code>sub001_pib_SUM50-70min.nii</code> <img src="../fig/aic_pet_imcalc_output.png" alt="ImCalc output" class="figure"></p></li>
<li><p><code>Output Directory</code> – specify the output directory for
the file. If you leave this blank, SPM will output the file in the
present working directory (i.e., the directory that SPM was launched
from in the command line)</p></li>
<li>
<p><code>Expression</code> – because the frames are all 5 minutes
long at this part of the sequence, we can simply take the average to sum
the last 20 minutes of counts.</p>
<p>Enter the expression</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">MATLAB<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode matlab" tabindex="0"><code class="sourceCode matlab"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>(<span class="va">i1</span> <span class="op">+</span> <span class="va">i2</span> <span class="op">+</span> <span class="va">i3</span> <span class="op">+</span><span class="va">i4</span>)<span class="op">/</span><span class="fl">4</span></span></code></pre>
</div>
<p>Note that taking the average of these frames is equivalent to summing
all of the detected counts across the frames and dividing by the total
amount of time that has passed during those frames (i.e., 20 min). <img src="../fig/aic_pet_imcalc_expression.png" alt="ImCalc expression" class="figure"></p>
</li>
<li><p><code>Data Matrix</code>, <code>Masking</code>,
<code>Interpolation</code> can all use default values</p></li>
<li><p><code>Data Type</code> – specify FLOAT32 <img src="../fig/aic_pet_imcalc_float.png" alt="Choose float image" class="figure"></p></li>
</ul>
</li>
<li><p>Verify ImCalc inputs and then run the batch by pressing the green
play button at the top of the batch editor. This should create a new
NIfTI file with the late-frame summed data.</p></li>
<li>
<p>Open the 50-70 min SUM image in FSLeyes and note the difference
in noise properties vs. those you observed in a single frame. (note: you
will likely need to use different thresholding to see the image; e.g.,
0-20,000 Bq/mL) The SNR has improved because we are now viewing an image
with more total counts. Notice that you can now more clearly see some
contrast between the precuneus and the adjacent occipital cortex in the
sagittal plane just to the left or right of mid-sagittal. You can
similarly see differences in intensity between much of the cortex and
the cerebellar GM, a common reference region used for amyloid PET as it
typically has negligible specific binding in the cerebellum.</p>
<p><strong>Do you think this person is amyloid positive or
negative?</strong></p>
</li>
<li>
<p>Repeat the above steps to generate the SUM image for the early
frame data. Make sure to remove the previous volumes before adding the
new volume in the Input Images. You will need to use the first seven
frames corresponding to the first 20 min of data. Note that the frames
are not all the same duration and a straight average is no longer
equivalent to summing all of the counts and dividing by the total time.
How can we use a weighted average to account for the differences in
frame durations between the first five and last two frames of the first
20 minutes?</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">MATLAB<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode matlab" tabindex="0"><code class="sourceCode matlab"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>(<span class="va">i1</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">i2</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">i3</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">i4</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span><span class="va">i5</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">i6</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span> <span class="va">i7</span><span class="op">*</span><span class="fl">5</span>) <span class="op">/</span> <span class="fl">20</span></span></code></pre>
</div>
</li>
<li><p>Name this file <code>sub001_pib_SUM0-20min.nii</code></p></li>
<li><p>Open the 0-20 min SUM image in FSLeyes and compare to the 50-70
min SUM image. Note the differences in GM/WM contrast between the images
and the differences in noise properties. You will likely have to change
the max intensity settings in both images to be able to observe the
differences in contrast.</p></li>
<li><p>Close the SPM batch editor</p></li>
</ol>
</div>
</section><section><h2 class="section-heading" id="image-smoothing">Image Smoothing<a class="anchor" aria-label="anchor" href="#image-smoothing"></a>
<a class="anchor" aria-label="anchor" href="#image-smoothing"></a>
</h2>
<hr class="half-width">
<p>As you can see from viewing the unsmoothed images, they are still
quite noisy, particularly at the voxel level. In this section we’ll use
a simple Gaussian smoothing kernel to reduce the voxel-level noise. We
are really trading voxel variance for co-variance between voxels. This
means that the activity concentration in any particular voxel will have
lower variance, but will be more influenced by neighboring voxels. Thus,
we are degrading the spatial resolution of the image slightly to improve
the noise characteristics. The size of the Gaussian smoothing kernel is
typically specified as the full-width of the kernel at half the maximum
value of the kernel.</p>
<div class="section level3">
<h3 id="apply-smoothing-to-sum-images">Apply smoothing to SUM images<a class="anchor" aria-label="anchor" href="#apply-smoothing-to-sum-images"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Click on the Smooth button to launch the Smooth module in SPM and
use the following inputs:
<ul>
<li>
<code>Image to Smooth</code> - Specify the two SUM images (you can
do both at the same time)</li>
<li>
<code>FWHM</code> – 4 4 4 (this specified an isotropic 4 mm
full-width half Gaussian smoothing kernel)</li>
<li>
<code>Data Type</code> – Same</li>
<li>
<code>Implicit Mask</code> – No</li>
<li>
<code>Filename prefix</code> – ‘s’ (this prepends an “s” onto the
filename to indicate the newly created image was smoothed)</li>
</ul>
</li>
<li>Press the green play button to run the smoothing module.</li>
<li>Close the SPM batch editor.</li>
<li>View the resultant smoothed images in FSL (the ones with an ‘s’
prefix in the filename). Note the reduction in voxel-level noise but
also the slight reduction in spatial resolution.</li>
</ol>
</div>
</section><section><h2 class="section-heading" id="intermodal-registration">Intermodal Registration<a class="anchor" aria-label="anchor" href="#intermodal-registration"></a>
<a class="anchor" aria-label="anchor" href="#intermodal-registration"></a>
</h2>
<hr class="half-width">
<p>While we can quantify PET images without anatomical data like
T1-weighted MRI, we can gain considerable regional detail if we align
our PET images to an anatomical reference. This section will use SPM12’s
<code>Coregister</code> module to register the PET data to a T1-weighted
MRI. We’ll first view the problem in FSL to demonstrate why we need to
register the images and then perform the co-registration to align the
PET data to the T1-w MRI.</p>
<div class="section level3">
<h3 id="view-images-in-fsl">View images in FSL<a class="anchor" aria-label="anchor" href="#view-images-in-fsl"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Open the <code>rsub001_t1mri.nii</code> and in FSL. Use the down
arrow next to the Overlay list to move the T1 to the bottom of the list.
Select the T1 and set the window min and max to 0 and 1,400,
respectively.</li>
<li>Select the smoothed 50-70 min SUM PIB image in the viewer and adjust
the min and max window level to 0 and 30,000 respectively. Select the
<code>Hot [Brain colours]</code> colormap for the PET image. Reduce the
Opacity slider down until you can see both the MRI in the background and
the PET image in the foreground.</li>
<li>Notice that the images are not aligned. Thus, we cannot yet use the
structural MRI to extract regional PET data. We first need to register
the PET image to the</li>
</ol>
</div>
<div class="section level3">
<h3 id="coregister-pet-to-t1-weighted-mri-">Coregister PET to T1-weighted MRI.<a class="anchor" aria-label="anchor" href="#coregister-pet-to-t1-weighted-mri-"></a>
</h3>
<p><strong>Caution: SPM will overwrite the transformation matrix in the
Source Image and Other Image! As such, we will first create a safe copy
of our SUM and 4D images before running the Coregistration
module).</strong></p>
<ol style="list-style-type: decimal">
<li>Create copies of the smoothed late-frame SUM image and the 4D pib
image.
<ol style="list-style-type: lower-alpha">
<li>
<p>In the terminal, create a new directory called “safe” in your
working directory.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">mkdir</span> safe</span></code></pre>
</div>
</li>
<li>
<p>Copy the <code>ssub001_pib_SUM50-70min.nii</code> and
<code>sub001_pib.nii</code> images to the safe directory using the cp
command in the terminal.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">cp</span> ssub001_pib_SUM50-70min.nii safe/ ssub001_pib_SUM50-70min.nii</span></code></pre>
</div>
</li>
</ol>
</li>
<li>Open the Coregistration module by selecting
<code>Coregister (Est &amp; Res)</code> from the Spatial pre- processing
drop down. This function will estimate the parameters needed to align
the source image to the reference image, write those transformations to
the NIfTI headers for those files and will create new images with the
image matrices resliced to align voxel- to-voxel with the reference
image.
<ul>
<li>Select <code>rsub001_t1mri.nii</code> for the reference image.</li>
<li>Select the smoothed 50-70 SUM image for the source image.
<code>ssub001_pib_SUM50-70min.nii</code>
</li>
<li>Optional: if you’d like to also apply this registration to the 4D
data, Select the 4D data for Other Images. You will need to enter each
volume in the 4D image to apply the transformation matrix to each frame
in the time series, or you can specify a subset of the frames to create
a 4D image with just some frames included.</li>
<li>We will use default values for <code>Estimation Options</code>
</li>
<li>In the <code>Reslice Options</code> Set Interpolation to “Trilinear”
and masking to “Mask Images”</li>
</ul>
</li>
<li>Press the green play button to register the PET data to MRI.</li>
</ol>
</div>
<div class="section level3">
<h3 id="review-registration-results">Review registration results<a class="anchor" aria-label="anchor" href="#review-registration-results"></a>
</h3>
<ol style="list-style-type: decimal">
<li>In FSL, remove all of the loaded images using the Overlay&gt;Remove
All command.</li>
<li>Open the T1-weighted MRI and the resliced registered SUM PET image
<code>rssub001_pib_SUM50-70min.nii</code> in FSLeyes.</li>
<li>Select the SUM image. Select the <code>Hot [Brain colours]</code>
colormap for the SUM PET image and set the min to 0 and max to
25,000.</li>
<li>Use the opacity slider to make the SUM PET image ~50%
translucent.</li>
<li>Scroll around in the image to view the registered SUM PET image
overlayed on the T1-weighted MRI. Notice the PET image now aligns with
the MRI. Also note the elevated binding in the precuneus, cingulate
cortex, and frontal, parietal and temporal cortices.</li>
<li>Also observe the registration accuracy by looking at features common
to (i.e., mutual information) both T1-weighted MRI and PiB PET. For
example, elevated non-specific PiB binding can be observed in the
cerebellar peduncles (white matter) and a lack of tracer uptake is
observed in the CSF filled spaces like the lateral ventricles which are
also low intensity on the T1-w MRI.</li>
<li>Compare the image headers for the SUM image in the safe directory
with the SUM image with the same name that was used as the source image
for registration. You can show the header info in the terminal using
<code>fslhd</code> or select Setting&gt;Ortho View1&gt;Overlay
Information in FSLeyes. Notice that the sform matrix parameters have
changed to reflect the spatial transformation needed to align the PET
image to the T1-weighted MRI. This allows a viewer to show the PET image
aligned to the T1-w image in world coordinates without having to alter
the image matrix.</li>
<li>Now compare the image headers for the resliced SUM image
<code>rssub001_pib_SUM50-70min.nii</code> with the T1-weighted MRI. The
matrix size and sform matrix should be identical. This is because SPM
resliced the PET image matrix such that the image matrix itself now
aligns with the T1-weighted MRI, and thus no transformation in the
header is needed to align the images in the viewer.</li>
</ol>
</div>
</section><section><h2 class="section-heading" id="create-a-standard-uptake-value-ratio-suvr-image">Create a standard uptake value ratio (SUVR) image<a class="anchor" aria-label="anchor" href="#create-a-standard-uptake-value-ratio-suvr-image"></a>
<a class="anchor" aria-label="anchor" href="#create-a-standard-uptake-value-ratio-suvr-image"></a>
</h2>
<hr class="half-width">
<p>In this section, we will use the registered sum image and the
T1-weighted MRI to create a cerebellum GM ROI and generate a parametric
SUVR image. We’ll do all of these steps using FSL commands and
functions. We’ll first create a hand-drawn ROI in the inferior
cerebellum based on the MRI, and then use this mask to intensity
normalize the SUM PET image and create our SUVR image. Note that we are
specifically using the 50-70 min SUM image to generate the SUVR image as
this is the timepoint wherein PiB has reached a pseudo “steady state”
wherein binding estimates are more stable.</p>
<div class="section level3">
<h3 id="create-a-hand-drawn-cerebellum-gm-roi">Create a hand-drawn cerebellum GM ROI<a class="anchor" aria-label="anchor" href="#create-a-hand-drawn-cerebellum-gm-roi"></a>
</h3>
<ol style="list-style-type: decimal">
<li>In <code>fsleyes</code>, turn off the PET overlay.</li>
<li>Turn on Edit mode by selecting Tools -&gt; Edit Mode</li>
<li>In the image viewer, navigate to the inferior portion of the
cerebellar GM (~Z voxel location 30). You should be 1-2 axial planes
below the inferior GM/WM boundary in the cerebellum.</li>
<li>Select the T1-w MRI in the Overlay list and click the icon on the
left side of the viewer that looks like a sheet of paper to create a 3D
mask using the T1-w image as a reference.</li>
<li>Rename the mask <code>rsub001_cblm_mask</code> using the text box on
the top-left side of FSLeyes</li>
<li>Using the pencil and fill tools, hand draw circles in the left and
right inferior cerebellum on the transaxial plane. Use the fill tool to
fill in the inner part of the circle. Ensure the Fill value is set to 1.
Using a Selection size of 3 voxels or greater will help draw the ROI
more easily. When you’re done drawing your ROI, click the select tool to
enable you to scroll around the image viewer.</li>
<li>Select the mask image and save the image (Overlay -&gt; Save) as a
new NIfTI file named <code>rsub001_cblm_mask.nii.</code>
</li>
</ol>
</div>
<div class="section level3">
<h3 id="create-the-suvr-image-with-the-inferior-cerebellum-reference-region">Create the SUVR Image with the inferior cerebellum reference
region<a class="anchor" aria-label="anchor" href="#create-the-suvr-image-with-the-inferior-cerebellum-reference-region"></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>For the expression, we want to divide the SUM 50-70 min pib image
by the mean intensity in the cerebellum ROI that we just generated by
hand. To accomplish this, we will divide the entire SUM pet image by the
mean of the SUM PET image in all voxels where the cerebellum mask =1.
We’ll do this in two steps using FSL.</p></li>
<li>
<p>In the command line, extract the mean activity concentration in
the cerebellum mask using fslstats</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">fslstats</span> rssub001_pib_SUM50-70min.nii <span class="at">-k</span> rsub001_cblm_mask.nii <span class="at">-M</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">5902.898170</span> </span></code></pre>
</div>
</li>
<li>
<p>Create the SUVR image by dividing the SUM 50-70min image by the
mean activity concentration output by <code>fslstats</code></p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">fslmaths</span> rssub001_pib_SUM50-70min.nii <span class="at">-div</span> {ROI mean} rssub001_pib_SUVR50-70min.nii</span></code></pre>
</div>
</li>
</ol>
</div>
<div class="section level3">
<h3 id="view-the-suvr-image-overlayed-on-the-t1-w-mri">View the SUVR image overlayed on the T1-w MRI<a class="anchor" aria-label="anchor" href="#view-the-suvr-image-overlayed-on-the-t1-w-mri"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Open the T1-weighted MRI (if not already opened) and the newly
created pib SUVR image <code>rssub001_pib_SUVR50-70min.nii</code> in
FSLeyes.</li>
<li>For the SUVR image, set the colormap to
<code>Hot [Brain colours]</code>, set the min and max intensity window
to 0 and 3, and set the opacity to ~50%.</li>
<li>Notice the values within the image have been rescaled and should be
roughly between 0 and 3 SUVR. For interpretation, values ~&gt;1 (plus
some noise) in the gray matter indicate specific tracer binding to
beta-amyloid plaques.</li>
</ol>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<ul>
<li><strong>Which regions do you suspect have amyloid
plaques?</strong></li>
<li><strong>Which regions have the highest density of amyloid
plaques?</strong></li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="stretch-exercises">Stretch Exercises<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
</h2>
<hr class="half-width">
<p>If you have time, please try the following challenge to test your
knowledge.</p>
<div id="suvr-versus-dvr-images" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="suvr-versus-dvr-images" class="callout-inner">
<h3 class="callout-title">SUVR versus DVR images<a class="anchor" aria-label="anchor" href="#suvr-versus-dvr-images"></a>
</h3>
<div class="callout-content">
<p>We have pre-processed the PiB image using a different image pipeline
that outputs distribution volume ratio (DVR) images instead of SUVR.
These are located in the folder
<code>~/data/PETImaging/ProcessedPiBDVR</code> in the file
<code>cghrsub001_pib_DVRlga.nii</code> Compare the DVR image with the
SUVR image you created in the tutorial.</p>
<p><em>How are the images similar and how are they different?</em></p>
</div>
</div>
</div>
<div id="accordionHint2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button hint-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseHint2" aria-expanded="false" aria-controls="collapseHint2">
  <h4 class="accordion-header" id="headingHint2"> Give me a hint </h4>
</button>
<div id="collapseHint2" class="accordion-collapse collapse" data-bs-parent="#accordionHint2" aria-labelledby="headingHint2">
<div class="accordion-body">
<p>Pay close attention to the display settings for the window and
colormap.</p>
</div>
</div>
</div>
</div>
<div id="create-a-tau-pet-suvr-image" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="create-a-tau-pet-suvr-image" class="callout-inner">
<h3 class="callout-title">Create a Tau PET SUVR image<a class="anchor" aria-label="anchor" href="#create-a-tau-pet-suvr-image"></a>
</h3>
<div class="callout-content">
<p>You have created a SUVR image for PiB, which used a dynamic
acquisition wherein the scan started at the same time as tracer
injection. Now see if you can repeat the relevant steps above to create
a SUVR image for the MK-6240 scan.</p>
</div>
</div>
</div>
<div id="accordionHint3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button hint-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseHint3" aria-expanded="false" aria-controls="collapseHint3">
  <h4 class="accordion-header" id="headingHint3"> Give me a hint </h4>
</button>
<div id="collapseHint3" class="accordion-collapse collapse" data-bs-parent="#accordionHint3" aria-labelledby="headingHint3">
<div class="accordion-body">
<p>You’ll need to look at the .json file for the TAU PET NIfTI file -
this will contain key information around timing and framing so that you
can determine which frames to SUM to generate the SUVR image. The most
commonly used MK-6240 SUVR windows are 70-90 min or 90-110 min
post-injection. For most tau tracers, the inferior cerebellum is a valid
reference region. If you run out of time and would like to view an
MK-6240 SUVR image, you can view the images in
<code>~/data/PETImaging/ProcessedTutorial</code>, which have been
pre-processed.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="additional-steps">Additional steps<a class="anchor" aria-label="anchor" href="#additional-steps"></a>
<a class="anchor" aria-label="anchor" href="#additional-steps"></a>
</h2>
<hr class="half-width">
<p>In the tutorial above, some steps that would typically be included in
PET processing were omitted to enable enough time to get through the
tutorial and create an SUVR image during the workshop. For example, we
did not include interframe alignment and did not perform any smoothing
or denoising on the 4D PET data. We have included additional steps below
and have also included some preprocessed PiB data using a DVR pipeline
that you can compare with your SUVR image.</p>
<div class="section level3">
<h3 id="interframe-realignment">Interframe realignment<a class="anchor" aria-label="anchor" href="#interframe-realignment"></a>
</h3>
<p>Interframe realignment is often included in processing 4D PET data to
correct for motion between frames in a dynamic acquisition. It’s
important to note that this process will not correct for motion that
happens within a PET frame and will also not correct for misalignment of
the emission scan and attenuation map used during the reconstruction. As
such, correcting for interframe motion does not entirely account for
motion that occurs during a PET scan. In cases with large amounts of
motion, the reconstructed data may need to throw out bad frames or may
simply be unusable. There are some approaches to correct for motion on
the scanner and prior to/during reconstruction, but this is beyond the
scope of this tutorial. We will use the 4D PiB data and SPM12 to perform
interframe realignment, but will modify our approach to account for
differences in PET frame duration and noise.</p>
<ol style="list-style-type: decimal">
<li>View the problem
<ol style="list-style-type: lower-alpha">
<li>In the previous tutorial, we created SUM images of the first and
last 20 minutes of the PiB acquisition. Load these images in FSLeyes.
Recall that you’ll need to use the 50-70 SUM image in the /safe
directory that did not have the coregistration transformation matrix
written to the NIfTI header. If you have not completed the tutorial, you
can load the following images that have been previously processed:
<ul>
<li><code>/home/as2-streaming-user/data/PET_Imaging/ProcessedTutorial/ssub001_pib_SUM0-20min.nii</code></li>
<li><code>/home/as2-streaming-user/data/PET_Imaging/ProcessedTutorial/safe/ssub001_pib_SUM50-70min.nii</code></li>
</ul>
</li>
<li>Set the threshold for the min and max window to 0 to 35,000 for the
0-20 min SUM image and 0 to 20,000 for the 50-70 min SUM image.</li>
<li>Toggle the top image on and off using the eye icon in the Overlay
list. Notice the slight rotation of the head in the sagittal plane
between the early and late frames. This is due to participant motion
during the scan acquisition and what we are going to attempt to correct
using interframe realignment.</li>
<li>Close FSLeyes.</li>
</ol>
</li>
<li>Launch SPM if not already opened</li>
<li>Smooth all frames of the 4D data – smoothing prior to realignment
will improve the registration by reducing voxel-level noise.
<ol style="list-style-type: lower-alpha">
<li>Select the Smooth module from SPM</li>
<li>Add all frames for the 4D PiB image <code>sub001_pib.nii</code> to
the Images to smooth</li>
<li>Set the FWHM to an isotropic 4 mm kernel (4 4 4).</li>
<li>Set the datatype to FLOAT32</li>
<li>Press the green play button to execute the smoothing operation</li>
<li>Close the smooth module in SPM</li>
<li>View the smoothed 4D PiB image in FSLeyes.</li>
</ol>
</li>
<li>SUM PET frames across the 4D acquisition
<ol style="list-style-type: lower-alpha">
<li><p>For interframe realignment, we typically create an average image
of the entire 4D time series to use as a reference image to align each
frame. Because the PiB framing sequence has different frame durations,
we cannot simply average the frames as we would in fMRI, but instead
need to create a SUM image of the entire 70-minute acquisition using a
weighted average.</p></li>
<li><p>Open the <code>ImCalc</code> module in SPM.</p></li>
<li><p>Specify all frames of the smoothed 4D PiB image (ssub001_pib.nii)
as Input Images. Be sure to maintain the frame order on the file
input.</p></li>
<li><p>Name the output file
<code>ssub001_pib_SUM0-70min.nii</code></p></li>
<li>
<p>For the expression, specify an equation for a frame
duration-weighted average of all frames. Recall that the frame durations
are stored in the .json file.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">MATLAB<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode matlab" tabindex="0"><code class="sourceCode matlab"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>(<span class="va">i1</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span><span class="va">i3</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span><span class="va">i4</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span><span class="va">i5</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span><span class="va">i6</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i7</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i8</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i9</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i10</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i11</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i12</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i13</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i14</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i15</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i16</span><span class="op">*</span><span class="fl">5</span> <span class="op">+</span><span class="va">i17</span><span class="op">*</span><span class="fl">5</span>)<span class="op">/</span><span class="fl">70</span></span></code></pre>
</div>
</li>
<li><p>Use FLOAT32 for the Data Type</p></li>
<li><p>Run the module using the green play arrow.</p></li>
<li><p>Close the SPM <code>ImCalc</code> module.</p></li>
</ol>
</li>
<li>Perform Interframe alignment using SPM12 realign
<ol style="list-style-type: lower-alpha">
<li>Open the Realign: Estimate and Reslice module in SPM12</li>
<li>Select data and click Specify</li>
<li>Select Session and click Specify
<ol style="list-style-type: lower-roman">
<li>Here we will use the SUM0-70 min image as the reference for
realignment. This is done by selecting this file first in the session
file input list.</li>
<li>Select the SUM 0-70 min PiB image, and then specify the entire
smoothed 4D time series by input each of the 17 frames.</li>
<li>Use default settings for all parameters except the following
<ul>
<li>
<code>Estimation Options-Smoothing (FWHM)</code>: 7</li>
<li>
<code>Estimation Options-Interpolation</code>: Trilinear</li>
<li>
<code>Reslice Options-Resliced Images</code>: Images 2..n</li>
<li>
<code>Reslice Options-Interpolation</code>: Trilinear</li>
</ul>
</li>
<li>Run the module by clicking the green play icon</li>
</ol>
</li>
<li>Once the process has completed, the SPM graphics window will output
the translation and rotation parameters used to correct for motion in
each frame. Note these are small changes typically &lt;1-2 mm
translation and &lt;2 degrees rotation.</li>
<li>Close the SPM realign module</li>
<li>View the resultant 4D image in FSLeyes
(<code>rssub001_pib.nii</code>) using a display min and max of 0 to
30,000. Navigate in the viewer to view the sagittal plane just off
mid-sagittal. Place your crosshairs at the most inferior part of the
orbitofrontal cortex and advance through the PET frames. How did the
realignment perform? Are you still seeing rotation in the sagittal plane
between early and late frames?</li>
<li>Now change the max window to 100 to saturate the image and view the
outline of the head. Scroll through the frames to look for any head
motion across the frames. To see the difference before and after
realignment, load the smoothed 4D image, saturate the image to view the
head motion between frames.</li>
</ol>
</li>
</ol>
</div>
</section><section><h2 class="section-heading" id="appendices-1-filenames-and-descriptions">Appendices 1: Filenames and descriptions<a class="anchor" aria-label="anchor" href="#appendices-1-filenames-and-descriptions"></a>
<a class="anchor" aria-label="anchor" href="#appendices-1-filenames-and-descriptions"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="filenames-and-descriptions">Filenames and Descriptions<a class="anchor" aria-label="anchor" href="#filenames-and-descriptions"></a>
</h3>
<p>Unprocessed files
(<code>/home/as2-streaming-user/data/PET_Imaging/UnprocessedData/</code>):</p>
<ul>
<li>
<code>rsub001_t1mri.nii</code> – T1-weighted MRI NIfTI image</li>
<li>
<code>sub001_mk6240.nii</code> – 4D [18F]MK-6240 PET NIfTI
image</li>
<li>
<code>sub001_pib.nii</code> – 4D [11C]PiB PET NIfTI image</li>
<li>
<code>sub001_mk6240.json</code> – metadata for MK-6240 PET scan</li>
<li>
<code>sub001_pib.json</code> – metadata for PiB PET scan</li>
</ul>
<p>Processed files in order of tutorial creation
(<code>/home/as2-streaming-user/data/PET_Imaging/ProcessedTutorial/</code>):</p>
<ul>
<li>PiB SUVR tutorial
<ul>
<li>
<code>sub001_pib_SUM50-70min.nii</code> – PiB PET summed from 50-70
min post-injection</li>
<li>
<code>sub001_pib_SUM0-20min.nii</code> – PiB PET summed from 0-20
min post-injection</li>
<li>
<code>ssub001_pib_SUM50-70min.nii</code> – SUM50-70 min PiB image
smoothed by 4mm kernel</li>
<li>
<code>ssub001_pib_SUM0-20min.nii</code> – SUM0-20 min PiB image
smoothed by 4mm kernel</li>
<li>
<code>rssub001_pib_SUM50-70min.nii</code> – smoothed SUM50-70 min
PiB image registered and resliced to T1-weighted MRI</li>
<li>
<code>rsub001_cblm_mask.nii.gz</code> – mask image of hand-drawn
cerebellum ROI</li>
<li>
<code>rssub001_pib_SUVR50-70min.nii</code> – PiB SUVR image
registered to T1-weighted MRI</li>
</ul>
</li>
<li>MK-6240 SUVR tutorial
<ul>
<li>
<code>sub001_mk6240_SUM70-90min.nii</code> – PiB PET summed from
70-90 min post-injection</li>
<li>
<code>ssub001_mk6240_SUM70-90min.nii</code> – SUM70-90 min MK-6240
image smoothed by 4mm kernel</li>
<li>
<code>rssub001_mk6240_SUM70-90min.nii</code> – smoothed SUM70-90 min
MK-6240 image registered and resliced to T1-weighted MRI</li>
<li>
<code>rssub001_mk6240_SUVR70-90min.nii.gz</code> – MK-6240 SUVR
image registered to T1-weighted MRI</li>
</ul>
</li>
</ul>
<p>Processed PiB DVR in order of creation
(<code>/home/as2-streaming-user/data/PET_Imaging/ProcessedPiBDVR/</code>):</p>
<ul>
<li>
<code>ssub001_pib.nii</code> – smoothed 4D PiB time series</li>
<li>
<code>sub001_pib_SUM0-70min.nii</code> – PiB SUM 0-70 min</li>
<li>
<code>rsub001_pib.nii</code> – realigned 4D PiB time series</li>
<li>
<code>hrsub001_pib.nii</code> – realigned 4D PiB time series with
HYPR denoising applied</li>
<li>
<code>hrsub001_pib_SUM0-20min.nii</code> – denoised PiB SUM 0-20 min
used for source image in SPM coregistration to T1-weighted MRI</li>
<li>
<code>cghrsub001_pib_SUM0-20min.nii</code> – denoised PiB SUM 0-20
min image coregistered and resliced to T1-weighted MRI</li>
<li>
<code>cghrsub001_pib.nii</code> - denoised 4D PiB image coregistered
and resliced to T1-weighted MRI</li>
<li>
<code>cghrsub001_pib_DVRlga.nii</code> – PiB DVR parametric image
coregistered to T1-weighted MRI (Logan graphical analysis, <span class="math inline">\(t^*\)</span>=35 min, <span class="math inline">\(k_2’\)</span>=0.149 <span class="math inline">\(min^{-1}\)</span>, cerebellum mask reference
region)</li>
<li>See the file descriptions earlier in the appendix for remaining
descriptions of images in this directory</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="pib-dvr-pipeline">PiB DVR Pipeline<a class="anchor" aria-label="anchor" href="#pib-dvr-pipeline"></a>
<a class="anchor" aria-label="anchor" href="#pib-dvr-pipeline"></a>
</h2>
<hr class="half-width">
<p>Smooth 4D data (3 mm) -&gt; SUM 0-70 min for realignment reference
-&gt; Interframe Realignment -&gt; HYPR Denoising -&gt; SUM 0-20 min for
coregistration source image -&gt; Coregister to MRI -&gt; Extract
cerebellum GM reference region time-activity curve -&gt; Generate
parametric DVR image</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>PET Images are reconstructed from listmode data.</li>
<li>The most commonly used PET tracers are sensitive to amyloid plaques
and neurofibrillary tau tangles.</li>
<li>Full dynamic scans are acquired from the time of injection, while
static scans are acquired a fixed interval after injection when the
tracer has or is approaching equilibrium</li>
<li>Summing individual frames together reduces the level of noise</li>
<li>SUVR images represent the relative uptake in each voxel to a
reference region, where there is likely no specific binding</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-diffusion-weighted-imaging"><p>Content from <a href="diffusion-weighted-imaging.html">Diffusion-weighted imaging (DWI)</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/diffusion-weighted-imaging.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What does diffusion weighted imaging measure?</li>
<li>What processing steps are needed when working with diffusion
weigthed imaging data?</li>
<li>What types of analyses are used with diffusion imaging in dementia
resaerch?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the processing steps in diffusion-weighted MRI scans</li>
<li>Perform basic analyses on white matter microstructure.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>We will use the FSL diffusion toolbox to perform the processing steps
that are core to most diffusion weighted imaging analyses:</p>
<ul>
<li>image visualization of raw data and analysis outputs,</li>
<li>eddy correction,</li>
<li>generation of diffusion tensor metrics brain maps,</li>
<li>tract-based spatial statistics,</li>
<li>you can also stretch your knowledge and familiarize yourself with
loops to run these commands on multiple subjects, all shown at the end
of this tutorial</li>
</ul>
<p>We are going to be working in the DiffusionMRI subfolder under data
in your home directory, <code>~/data/DiffusionMRI</code>.</p>
</section><section><h2 class="section-heading" id="looking-at-the-raw-data">Looking at the raw data<a class="anchor" aria-label="anchor" href="#looking-at-the-raw-data"></a>
<a class="anchor" aria-label="anchor" href="#looking-at-the-raw-data"></a>
</h2>
<hr class="half-width">
<p>From the previous lessons, you learned how to view and navigate
images, let’s first look at the raw data, which can all be found under
<code>~/data/DiffusionMRI/sourcedata</code>.</p>
<p>To go to this directory using the terminal, use the command
<code>cd</code> to change directory. Type
<code>cd  ~/data/DiffusionMRI/sourcedata</code> to go this
directory.</p>
<p>Let’s inspect what each participant’s dwi directory should
contain:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">ls</span> sub-OAS30001/dwi</span></code></pre>
</div>
<p>or</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">ls</span> sub-OAS<span class="pp">*</span>/dwi</span></code></pre>
</div>
<p>The <code>*</code> will match any following text, which here will
list the contents of any directory starting with “sub-OAS”.</p>
<p>Each directory should contain 4 files:</p>
<ul>
<li>one <code>.bval</code> text file</li>
<li>one <code>.bvec</code> text file</li>
<li>one <code>.json</code> text file</li>
<li>one nifti (<code>.nii.gz</code>) image file</li>
</ul>
<p>All files are required for processing DWI data except the .json file.
The <code>.json</code> file is specific to the <a href="https://bids.neuroimaging.io/" class="external-link">BIDS</a> data organization, and is
a useful way to access data description. More and more software are also
relying on data organized according to the BIDS structure.</p>
<p>Let’s look at those files:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Change directory to go in one participant's folder</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="bu">cd</span> sub-OAS30001/dwi</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">## Image file</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="ex">fsleyes</span> sub-OAS30001_dwi.nii.gz</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a> </span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">## Text files</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="fu">cat</span> sub-OAS30001_ses-d2430_dwi.bval</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="fu">cat</span> sub-OAS30001_ses-d2430_dwi.bvec</span></code></pre>
</div>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div> The command should show the following content </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<figure><img src="../fig/bval_bvec.png" alt="example of bval and bvec file" class="figure mx-auto d-block"></figure><ul>
<li>The nifti file is a 4D file of all the directions acquired.</li>
<li>The <code>.bval</code> file refers to the <em>b-value</em> applied
to each image.</li>
<li>The <code>.bvec</code> file refers to the <em>vector</em> applied to
each image, with the coordinates in x, y and z.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge1"></a>
</h3>
<div class="callout-content">
<p>Use the “movie” option in fsleyes to look at all frames of the nifti
file. How can you know how many directions it contains?</p>
</div>
</div>
</div>
<div id="accordionHint1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button hint-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseHint1" aria-expanded="false" aria-controls="collapseHint1">
  <h4 class="accordion-header" id="headingHint1"> Give me a hint </h4>
</button>
<div id="collapseHint1" class="accordion-collapse collapse" data-bs-parent="#accordionHint1" aria-labelledby="headingHint1">
<div class="accordion-body">
<p>Refer to the <a href="imaging-data-structure-and-formats.html">Getting started
session</a> for more details!</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>There is 1 b0 image and 64 gradient images! You can check for the
maximum number as you move through the “Volume” box as shown below.</p>
<figure><img src="../fig/fsleyes_b0.png" alt="FSLeyes of B0 image" class="figure mx-auto d-block"></figure>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="data-preprocessing">Data preprocessing<a class="anchor" aria-label="anchor" href="#data-preprocessing"></a>
<a class="anchor" aria-label="anchor" href="#data-preprocessing"></a>
</h2>
<hr class="half-width">
<p>We are now ready to start data pre-processing, which we will do using
the FSL Diffusion Toolbox. Most of the steps and explanation below are
adapted from the excellent tutorial provided FSL, please refer to it for
more details: <a href="https://open.win.ox.ac.uk/pages/fslcourse/practicals/fdt1/index.html" class="external-link uri">https://open.win.ox.ac.uk/pages/fslcourse/practicals/fdt1/index.html</a></p>
<p>All the steps below will be done on one subject only, but if you wish
to loop the different steps across multiple participants, refer to the
section <a href="#stretch-your-knowledge">Stretch your knowledge</a> at
the end.</p>
<div class="section level3">
<h3 id="creating-a-brain-mask-from-the-b0-images">1. Creating a brain mask from the b0 images<a class="anchor" aria-label="anchor" href="#creating-a-brain-mask-from-the-b0-images"></a>
</h3>
<p>We often use the b0 images (there is only 1 b0 image in this dataset)
to create a brain mask that is needed in future steps. First select the
b0 image, extract the brain only and binarize it to make a mask.</p>
<ul>
<li>
<p>Extract the b0 image only with select_dwi_vols or fslroi</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Usage: fslroi &lt;input&gt; &lt;output&gt; &lt;tmin&gt; &lt;tsize&gt;</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">fslroi</span> sub-OAS30001_dwi.nii.gz sub-OAS30001_b0.nii.gz 0 1</span></code></pre>
</div>
</li>
<li>
<p>Brain extraction and binarization with bet</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Usage: bet &lt;input&gt; &lt;output&gt; [options] </span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co"># the -m option will automatically create a binarized mask after brain extraction</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="ex">bet</span> sub-OAS30001_b0.nii.gz sub-OAS30001_b0_bet <span class="at">-m</span></span></code></pre>
</div>
</li>
<li>
<p>Load the mask you just created to make sure it is adequate!</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">fsleyes</span> sub-OAS30001_b0_bet_mask.nii.gz</span></code></pre>
</div>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="correcting-for-susceptibility-induced-distortions">2. Correcting for susceptibility-induced distortions<a class="anchor" aria-label="anchor" href="#correcting-for-susceptibility-induced-distortions"></a>
</h3>
<p>Some parts of the brain can appear distorted depending on their
magnetic properties. One common way to correct the distortions with DWI
data is by acquiring a b0 image acquired with a different
phase-encoding, and merging the two types of images running <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup" class="external-link">TOPUP</a>.</p>
<p>In this dataset we don’t have the data required for TOPUP so we will
skip this step.</p>
<p><em>Note however that you should run it if your data allows.</em></p>
</div>
<div class="section level3">
<h3 id="correcting-for-eddy-currents-and-movement">3. Correcting for eddy currents and movement<a class="anchor" aria-label="anchor" href="#correcting-for-eddy-currents-and-movement"></a>
</h3>
<p>Eddy is a tool to correct for eddy current-induced distortions and
movement on the image. Eddy currents arise from electric current due to
strong and fast changing gradients. Eddy also does outlier detection and
will replace signal loss by non-parametric predictions.</p>
<p>We need to create 2 files to be able to run eddy:</p>
<ul>
<li>an index file corresponding to the directions with the same phase
encoding</li>
<li>a file with some acquisition parameters</li>
</ul>
<p>Run the following lines to create the index file. Since all images
are obtained with the same phase encoding, it will just be a vector with
values of 1 of the same length of the bval file.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">## The command wc (wordcount) will check the length of the bval file and we will use this output to create the index file we need.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">wc</span> <span class="at">-w</span> sub-OAS30001_dwi.bval</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="va">indx</span><span class="op">=</span><span class="st">""</span> </span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="cf">for</span> <span class="kw">((</span><span class="va">i</span><span class="op">=</span><span class="dv">1</span><span class="kw">;</span> <span class="va">i</span><span class="op">&lt;=</span><span class="dv">65</span><span class="kw">;</span> <span class="va">i</span><span class="op">+=</span><span class="dv">1</span><span class="kw">));</span> <span class="cf">do</span> <span class="va">indx</span><span class="op">=</span><span class="st">"</span><span class="va">$indx</span><span class="st"> 1"</span><span class="kw">;</span> <span class="cf">done</span> </span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="bu">echo</span> <span class="va">$indx</span> <span class="op">&gt;</span> index.txt</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1 1 1 1 1 1 ... 1
The index file is a series of 1 repeated 65 times</code></pre>
</div>
<p>The acquisition parameter file is a vector containing the phase
encoding and the total read out time, which can all be found in the
<code>.json</code> file. Do <code>cat sub-OAS30001_dwi.json</code> and
see if you can find the following information.</p>
<ul>
<li>TotalReadoutTime: 0.0451246</li>
<li>PhaseEncodingDirection: j- : This corresponds to the AP direction
and is coded as -1 for the acquisition parameter file.</li>
</ul>
<p>You can also try
<code>cat sub-OAS30001_dwi.json | grep 'Total'</code> to directly find
the entry you need!</p>
<p>The acquisition parameter file first includes the phase encoding,
with the first 3 numbers corresponding to the x, y, and z directions.
Here we are acquiring along the y direction (being -1), and x and z
being 0. The last number is the total read out time.</p>
<p>To create it you can do:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="bu">printf</span> <span class="st">"0 -1 0 0.0451246"</span> <span class="op">&gt;</span> acqparams.txt</span></code></pre>
</div>
<p>We are ready to run eddy! Please refer to <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy" class="external-link uri">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy</a> for all the
details</p>
<p>However, eddy takes a long time to run (about 40 minutes either on
the VM or on a MacBook Pro), so we’ve run it for a few subjects already.
The outputs can be found in
<code>~/data/DiffusionMRI/processed_sourcedata</code>.</p>
<p>As eddy creates a lot of output files, it can be good practice to
create a separate directory to store the outputs so we keep things more
organized, as done in the <code>processed_sourcedata</code> directory.
For example, if you type
<code>ls ~/data/DiffusionMRI/processed_sourcedata/sub-OAS30001/eddy/</code>
you will see all the eddy outputs for this given participant.</p>
<p>Eddy also takes a lot of input arguments, as depicted below<br><img width="570" alt="eddy" src="https://user-images.githubusercontent.com/19730876/177518376-64bceb1e-d1ee-4a29-b694-7f0aa8095019.png" class="figure"><br><em>Image adapted from <a href="https://open.win.ox.ac.uk/pages/fslcourse/practicals/fdt1/index.html" class="external-link uri">https://open.win.ox.ac.uk/pages/fslcourse/practicals/fdt1/index.html</a></em></p>
<p>If you want to try to run it on one participant, you can try the
following command.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="ex">eddy</span> <span class="at">--imain</span><span class="op">=</span>sub-OAS30001_dwi.nii.gz <span class="at">--mask</span><span class="op">=</span>sub-OAS30001_b0_bet_mask.nii.gz <span class="at">--acqp</span><span class="op">=</span>acqparams.txt <span class="at">--index</span><span class="op">=</span>index.txt <span class="at">--bvecs</span><span class="op">=</span>sub-OAS30001_dwi.bvec <span class="at">--bvals</span><span class="op">=</span>sub-OAS30001_dwi.bval <span class="at">--out</span><span class="op">=</span>../eddy/eddy_corrected</span></code></pre>
</div>
<p>To be able to run the next step, we will copy the eddy-corrected DWI
scan for one subject into our working directory. Make sure you are in
this directory:
<code>~/data/DiffusionMRI/sourcedata/sub-OAS30001/dwi</code> (you can
use the command <code>pwd</code> to print your working directory and
know where you are), and then type this command:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">cp</span> ~/data/DiffusionMRI/processed_sourcedata/sub-OAS30001/eddy/sub-OAS30001_eddy_corrected.nii.gz .</span></code></pre>
</div>
<p>Now let’s compare the raw DWI scan vs. after eddy correction. You can
load the two images (sub-OAS30001_dwi.nii.gz and
sub-OAS30001_eddy_corrected.nii.gz) with <code>fsleyes</code>. On this
participant with high quality images, the differences are not really
noticeable, but remember the example from the webinar on data where
there was signal loss and big differences were evident.</p>
<p>** <strong>It’s always important to inspect images after
preprocessing steps! Many software (including FSL) have automated QC
frameworks available to help go through all the outputs. You can find
more information on eddyQC from the <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc" class="external-link">FSL
documentation</a> if you want to try it</strong></p>
</div>
<div class="section level3">
<h3 id="generating-dti-outputs">4. Generating DTI outputs<a class="anchor" aria-label="anchor" href="#generating-dti-outputs"></a>
</h3>
<p>We can now fit the diffusion tensor model to the preprocessed data.
This will generate all the standard DTI outputs, like fractional
anisotropy (FA), mean diffusivity (MD), radial diffusivity (RD) and
axial diffusivity (AD), along with eigenvectors.</p>
<p>As this will also generate many outputs, to keep things organized
let’s create a directory for storing the outputs.</p>
<p>The command is <code>dtifit</code>, and uses the eddy-corrected data
as input. All the inputs required are detailed in the command usage.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co">#Usage: Compulsory arguments (You MUST set one or more of):</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="co">#	-k,--data	dti data file</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="co"># -o,--out	Output basename</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># -m,--mask	Bet binary mask file</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co"># -r,--bvecs	b vectors file</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co"># -b,--bvals	b values file</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="ex">dtifit</span> <span class="at">--data</span><span class="op">=</span>sub-OAS30001_eddy_corrected.nii.gz <span class="at">--mask</span><span class="op">=</span>sub-OAS30001_b0_bet_mask.nii.gz <span class="at">--bvecs</span><span class="op">=</span>sub-OAS30001_dwi.bvec <span class="at">--bvals</span><span class="op">=</span>sub-OAS30001_dwi.bval <span class="at">--out</span><span class="op">=</span>../dti/sub-OAS30001_</span></code></pre>
</div>
<p>Many files have been created, let’s look at the ones most commonly
used, i.e. FA, MD and V1.<br>
V1 is the principal eigenvector and corresponds to the direction along
the principal diffusion direction and allows us to visualize the
underlying orientation of white matter fibers.</p>
<p>V1 should open as an RGB map where the colors represent
directions:<br>
* Red= left - right axis<br>
* Green= anterior - posterior axis<br>
* Blue= superior - inferior axis</p>
<p>You can also change the overlay type and visualize the image as lines
with ‘3-direction vector image (Line)’ in the top left corner, which
will show the vector field.</p>
<p>Example of the V1 file in RGB:<br><img width="863" alt="example_RGB_V1" src="https://user-images.githubusercontent.com/19730876/177555280-8ac7ec4b-b1bc-4b0d-9a6a-0a69a01d6dc3.png" class="figure"></p>
<p>We have now completed the basic steps required for all diffusion
data! Those allow to continue with further processing
(e.g. tractography) or to continue with group-level analyses, which
require processing a few subjects.</p>
<p>In the next section, you have a few options to go further:</p>
<ul>
<li>There is some example of code to perform the same steps as we did
above, this time looping across subjects.</li>
<li>A common analyses is <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS" class="external-link">Tract-Based Spatial
Statistics (TBSS)</a>, which allows for voxel-wise analyses on a
skeletonized white matter template. We provided the command lines below
to do such analyses. Some steps can take some time to run, and thus we
provided the outputs in <code>~/data/DiffusionMRI/tbss</code> if you
want to examine the different steps and the final outputs.</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="stretch-your-knowledge">Stretch your knowledge<a class="anchor" aria-label="anchor" href="#stretch-your-knowledge"></a>
<a class="anchor" aria-label="anchor" href="#stretch-your-knowledge"></a>
</h2>
<hr class="half-width">
<div id="do-you-want-to-process-multiple-subjects" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="do-you-want-to-process-multiple-subjects" class="callout-inner">
<h3 class="callout-title">Do you want to process multiple subjects?<a class="anchor" aria-label="anchor" href="#do-you-want-to-process-multiple-subjects"></a>
</h3>
<div class="callout-content">
<p>An easy way to do this is through multiple bash loops, introduced
this morning. You will have examples below of loops for the different
steps we did above if you want to try it.</p>
<p>Make sure you are in the following directory:
<code>~/data/DiffusionMRI/sourcedata</code></p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Extract the b0 image</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sub-OAS30<span class="pp">*</span><span class="kw">;</span> <span class="cf">do</span> <span class="bu">echo</span> <span class="va">$x</span><span class="kw">;</span> <span class="ex">fslroi</span> <span class="va">$x</span>/dwi/<span class="pp">*</span>_dwi.nii.gz <span class="va">$x</span>/dwi/<span class="va">${x}</span>_b0.nii.gz 0 1<span class="kw">;</span> <span class="cf">done</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#Create the brain mask from the b0 image</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sub-OAS30<span class="pp">*</span><span class="kw">;</span> <span class="cf">do</span> <span class="bu">echo</span> <span class="va">$x</span><span class="kw">;</span> <span class="ex">bet</span> <span class="va">$x</span>/dwi/<span class="pp">*</span>_b0.nii.gz <span class="va">$x</span>/dwi/<span class="va">${x}</span>_b0_bet <span class="at">-m</span><span class="kw">;</span> <span class="cf">done</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co"># Run eddy - Don't try this on multiple subjects; it will take too long to run!</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sub-OAS30<span class="pp">*</span><span class="kw">;</span> <span class="cf">do</span> <span class="bu">echo</span> <span class="va">$x</span><span class="kw">;</span> <span class="ex">eddy</span> <span class="at">--imain</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_dwi.nii.gz <span class="at">--mask</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_b0_bet_mask.nii.gz <span class="at">--acqp</span><span class="op">=</span>acqparams.txt <span class="at">--index</span><span class="op">=</span>index.txt <span class="at">--bvecs</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_dwi.bvec <span class="at">--bvals</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_dwi.bval <span class="at">--out</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_eddy_corrected<span class="kw">;</span> <span class="cf">done</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co"># Run dtifit</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> sub-OAS30<span class="pp">*</span><span class="kw">;</span> <span class="cf">do</span> <span class="bu">echo</span> <span class="va">$x</span><span class="kw">;</span> <span class="ex">dtifit</span> <span class="at">--data</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_eddy_corrected.nii.gz <span class="at">--mask</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_b0_bet_mask.nii.gz <span class="at">--bvecs</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_dwi.bvec <span class="at">--bvals</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span>_dwi.bval <span class="at">--out</span><span class="op">=</span><span class="va">$x</span>/dwi/<span class="va">${x}</span> <span class="kw">;</span> <span class="cf">done</span></span></code></pre>
</div>
<p><em>Note that all processed data can be found in
<code>~/data/DiffusionMRI/processed_sourcedata</code> if you want to
access it</em></p>
</div>
</div>
</div>
<div id="do-you-want-to-investigate-microstructure-differences-between-groups" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="do-you-want-to-investigate-microstructure-differences-between-groups" class="callout-inner">
<h3 class="callout-title">Do you want to investigate microstructure differences between groups?<a class="anchor" aria-label="anchor" href="#do-you-want-to-investigate-microstructure-differences-between-groups"></a>
</h3>
<div class="callout-content">
<p>Let’s investigate FA differences between 4 Controls and 4 AD subjects
using <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS/UserGuide" class="external-link">TBSS</a>.
This involves a few easy steps, which are outline below, but please
refer to the original description of TBSS for all details.</p>
<p>It can take some time to run, so we placed all outputs in
<code>~/data/DiffusionMRI/tbss</code> if you want to explore the outputs
from each step.<br></p>
<p>If you want to try it on your own, you can follow these steps:</p>
<ol style="list-style-type: decimal">
<li>
<p>Create a new directory for TBSS and copy all FA maps in it</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">mkdir</span> tbss_tutorial</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">cp</span> ~/data/DiffusionMRI/processed_sourcedata/sub-OAS30<span class="pp">*</span>/dti/<span class="pp">*</span>FA.nii.gz tbss_tutorial/</span></code></pre>
</div>
<p>You can run <code>slicesdir *.nii.gz</code> and open the resulting
web page report; this is a quick way to check your images.</p>
<p>Run all the next commands directly from the tbss_tutorial directory
you created.</p>
</li>
<li>
<p>Quick preprocessing of the data</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="ex">tbss_1_preproc</span> <span class="pp">*</span>.nii.gz</span></code></pre>
</div>
</li>
<li>
<p>Register all FA maps to standard space</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="ex">tbss_2_reg</span> <span class="at">-T</span></span></code></pre>
</div>
</li>
<li>
<p>Apply transformation to all images and create mean FA
skeleton</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">tbss_3_postreg</span> <span class="at">-S</span></span></code></pre>
</div>
<p>You can load the 4D file created <code>all_FA</code> with the overlay
<code>mean_FA_skeleton</code> on top to verify that all images are
aligned correctly.</p>
</li>
<li>
<p>threshold FA skeleton<br>
This last step is to threshold the FA skeleton that was created, inspect
it before and adapt accordingly (here we used the recommended 0.2
threshold)</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="ex">tbss_4_prestats</span> 0.2</span></code></pre>
</div>
</li>
</ol>
<p>We are now ready to do the statistical comparisons!</p>
<div class="section level3">
<h3 id="statistical-comparisons-between-two-groups">Statistical comparisons between two groups<a class="anchor" aria-label="anchor" href="#statistical-comparisons-between-two-groups"></a>
</h3>
<p>We will use the tool <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide" class="external-link">randomise</a>,
for which we need to create two text files: design.mat and design.con.
<strong>Design.mat</strong> specifies which groups the participants
belong to and other covariates of interest. <strong>Design.con</strong>
specifies the contrasts we want to perform for our statistical
analyses.</p>
<p>You need to make sure of the order of your FA images to create the
design matrix files, which is the alphabetical order. In this example,
we will compare Controls vs. AD patients. The diagnosis for each
participant is as follows:<br>
sub-OAS30001 : Control<br>
sub-OAS30003 : Control<br>
sub-OAS30006 : Control<br>
sub-OAS30024 : AD<br>
sub-OAS30025 : Control<br>
sub-OAS30128 : AD<br>
sub-OAS30217 : AD<br>
sub-OAS30262 : AD</p>
<p>We want to perform 2-sample t-test. We can create the files we need
easily with:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co"># Move to the stats directory</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="ex">design_ttest2</span> design 4 4</span></code></pre>
</div>
<p><strong>Since the order of our participants do not perfectly follow
the Diagnosis categories, make sure you fix the design.mat accordingly
if you used the automated command.</strong> The final one should
be:<br>
1 0<br>
1 0<br>
1 0<br><strong>0 1</strong><br><strong>1 0</strong><br>
0 1<br>
0 1<br>
0 1</p>
<p>For the design.con, the first contrast ‘1 -1’ will give results where
CU &gt; AD and the second contrast ‘-1 1’ will give results where the CU
&lt; AD. <em>Remember: we are looking at differences in FA, so we expect
smaller FA values in AD than Controls. It would be the opposite if we
were looking at differences in MD.</em></p>
<p>We are ready do run the command <code>randomise</code> to compare
groups. There are a lot of options you can choose to generate your
results, with different thresholding options. Please refer to the full
description of the command</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co">#Usage: randomise -i &lt;input&gt; -o &lt;output&gt; -d &lt;design.mat&gt; -t &lt;design.con&gt; [options]</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co"># Since we have only a few subjects we can apply a less stringent threshold, setting a cluster-based threshold at t= 1.5</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="ex">randomise</span> <span class="at">-i</span> all_FA_skeletonised <span class="at">-o</span> tbss <span class="at">-m</span> mean_FA_skeleton_mask <span class="at">-d</span> design.mat <span class="at">-t</span> design.con <span class="at">-c</span> 1.5</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co"># Here is the example to apply the preferred method of TFCE (threshold free cluster enhancement; option T2)</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="ex">randomise</span> <span class="at">-i</span> all_FA_skeletonised <span class="at">-o</span> tbss <span class="at">-m</span> mean_FA_skeleton_mask <span class="at">-d</span> design.mat <span class="at">-t</span> design.con <span class="at">-n</span> 100 <span class="at">--T2</span> <span class="at">-V</span></span></code></pre>
</div>
<p>We generated outputs using the two methods (cluster based threshold
of TFCE), which you can access under
<code>~/data/DiffusionMRI/tbss/stats</code>. You have:<br>
* unthresholded t-statistical maps,
<code>tbss_tstat1 and tbss_tstat2</code>, where 1 and 2 refer to the
different contrasts<br>
* p-values maps corrected for multiple comparisons (either
tbss_clustere_corrp_tstatX or tbss_tfce_corrp_tstatX)<br>
Note that the p-values maps are outputted as 1-p for convenience of
display (so that higher values are more significant). You can threshold
those from 0.95 to 1.</p>
<p>Here is one example of how you can overlay different outputs images
to visualize results.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="ex">fsleyes</span> <span class="at">-std1mm</span> mean_FA_skeleton <span class="at">-cm</span> green <span class="at">-dr</span> .3 .7 tbss_tstat1 <span class="at">-cm</span> red-yellow <span class="at">-dr</span> 1.5 3 tbss_clustere_corrp_tstat1 <span class="at">-cm</span> blue-lightblue <span class="at">-dr</span> 0.90 1</span></code></pre>
</div>
<p>This will display the standard MNI brain, the average FA skeleton
used for TBSS, the t-map for contrast 1 and the p-value maps after
cluster-based thresholding. <em>Note that I am thresholding the latter
from 0.90 to 1 since we have weak results in this example; this will
show voxels where CU have greater FA than AD patients from
p=0.10.</em></p>
<p>Try the same thing with the other contrast to confirm if results are
as expected.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Diffusion imaging is used to obtain measurements of tissue
microstructure</li>
<li>DWI consists of a 4D volume, and files describing the vectors and
b-values that each volume is encoding</li>
<li>The common core processing steps are: brain masking, susceptibility
correction, eddy/motion correction, and modelling (tensor fitting,
NODDI, etc)</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-functional-mri"><p>Content from <a href="functional-mri.html">Functional Magnetic Resonance Imaging (fMRI)</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/functional-mri.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What generates the signal that fMRI is measuring?</li>
<li>What preprocessing steps are needed before analysing fMRI data?</li>
<li>What type of analysis can I perform on pre-processed fMRI data?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Explain main sources of variability in BOLD signal and how to handle
them</li>
<li>Demonstrate basic pre-processing steps commonly used in fMRI</li>
<li>Get to know what type of information we can obtain from
pre-processed data (e.g. resting state networks)</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>Functional Magnetic Resonance Imaging (fMRI) is a technique that
captures a “movie” of brain activation over a certain period of time.
fMRI sequences are <em>time series</em> (4D acquisitions) of 3D brain
volumes. fMRI measures the blood-oxygen-level-dependent
(<strong>BOLD</strong>) signal, an indirect measure of regional brain
metabolism.</p>
<p>Raw resting-state functional MRI images are prone to several
artifacts and variability sources. For this reason, before performing
our statistical analysis, we need to apply a series of procedures that
aim at removing the sources of signal that we are not interested in, to
clean the ones we want to study. All these procedures together are
called <em>pre-processing</em>. This document will guide you through the
basic steps that are usually taken in the rs-fMRI pre-processing
phase.</p>
</section><section><h2 class="section-heading" id="pre-processing-software">Pre-processing Software<a class="anchor" aria-label="anchor" href="#pre-processing-software"></a>
<a class="anchor" aria-label="anchor" href="#pre-processing-software"></a>
</h2>
<hr class="half-width">
<p>To date, a large amount of pre-processing software packages are
available and can be freely used. In this course, we will use <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki" class="external-link">FSL</a> to perform
pre-processing steps directly from the command line.</p>
</section><section><h2 class="section-heading" id="data">Data<a class="anchor" aria-label="anchor" href="#data"></a>
<a class="anchor" aria-label="anchor" href="#data"></a>
</h2>
<hr class="half-width">
<p>In this tutorial, we are going to use data from one participant of
the OASIS study. Data can be found in the folder
<code>oasis/fMRI_tutorial_orig</code> First, let’s go into the directory
where the functional data are!</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">cd</span>   data/FunctionalMRI </span></code></pre>
</div>
<p>Now go into the subject folder and list the content to have an idea
of what data we are going to use.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="bu">cd</span> sub-OAS30015</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="fu">ls</span> </span></code></pre>
</div>
<p>As you can see, for fMRI processing we need high-resolution
structural data (T1w in the subfolder called <code>anat</code>) and fMRI
files, in the <code>func</code> subfolder.</p>
</section><section><h2 class="section-heading" id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<hr class="half-width">
<p>Modern fMRI pre-processing pipelines include a variety of processes
that can, or cannot, be performed depending on the acquired data
quality, and study design. Today, we will have a look at some of these
pre-processing steps that are most commonly used. Typical pre-processing
steps include:</p>
<ul>
<li>EPI Distortion Correction</li>
<li>Motion Correction</li>
<li>Standard Space Mapping</li>
<li>Spatial Smoothing</li>
<li>Temporal Filtering</li>
<li>Denoising</li>
</ul></section><section><h2 class="section-heading" id="hands-on">Hands-on<a class="anchor" aria-label="anchor" href="#hands-on"></a>
<a class="anchor" aria-label="anchor" href="#hands-on"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="structural-processing">Structural Processing<a class="anchor" aria-label="anchor" href="#structural-processing"></a>
</h3>
<p>Given the low spatial resolution and SNR of fMRI images, some
registration steps in functional processing involve the use of
previously computed transformation during the T1w processing. Important
steps to have performed are:</p>
<p><strong>In this course, these steps have already been performed for
you as they can take quite some time. Please don’t run these
commands!</strong></p>
<ul>
<li>
<p>Brain extraction with BET</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">bet</span> sub-OAS30015_T1w.nii.gz sub-OAS30015_T1w_bet <span class="at">-f</span> 0.4</span></code></pre>
</div>
</li>
<li>
<p>Tissue Segmentation with FAST</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">fast</span> <span class="at">-n</span> 3 <span class="at">-b</span> <span class="at">-o</span> sub-OAS30015_T1w_bet_FAST sub-OAS30015_T1w_bet.nii.gz</span></code></pre>
</div>
</li>
<li>
<p>Linear and Non linear T1w to MNI Standard Space Mapping</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">flirt</span> <span class="at">-in</span> sub-OAS30015_T1w_bet.nii.gz  <span class="at">-ref</span> /usr/local/fsl/data/standard/MNI152_T1_2mm_brain <span class="at">-out</span> highres2standard <span class="at">-omat</span> highres2standard.mat <span class="at">-cost</span> corratio <span class="at">-dof</span> 12 <span class="at">-searchrx</span> <span class="at">-90</span> 90 <span class="at">-searchry</span> <span class="at">-90</span> 90 <span class="at">-searchrz</span> <span class="at">-90</span> 90 <span class="at">-interp</span> trilinear</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="ex">fnirt</span> <span class="at">--iout</span><span class="op">=</span>highres2standard_head <span class="at">--in</span><span class="op">=</span>sub-OAS30015_T1w.nii.gz <span class="at">--aff</span><span class="op">=</span>highres2standard.mat <span class="at">--cout</span><span class="op">=</span>highres2standard_warp  <span class="at">--jout</span><span class="op">=</span>highres2highres_jac <span class="at">--config</span><span class="op">=</span>T1_2_MNI152_2mm <span class="at">--ref</span><span class="op">=</span>/usr/local/fsl/data/standard/MNI152_T1_2mm <span class="at">--refmask</span><span class="op">=</span>/usr/local/fsl/data/standard/MNI152_T1_2mm_brain_mask.nii.gz <span class="at">--warpres</span><span class="op">=</span>10,10,10</span></code></pre>
</div>
</li>
</ul>
<p>The results from these commands can be found in the /anat folder
within the subject directory</p>
</div>
<div class="section level3">
<h3 id="look-at-the-raw-data">Look at the raw data!<a class="anchor" aria-label="anchor" href="#look-at-the-raw-data"></a>
</h3>
<p>To have an idea of how the raw data looks before any pre-processing
is performed, let us visually review the images. To do so,
<code>fsleyes</code> is a great toolbox that can be used by typing on
the command line:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">fsleyes</span> func/sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="kw">&amp;</span></span></code></pre>
</div>
<p>As mentioned in the <a href="./imaging-data-structure-and-formats.html">imaging data</a>
section, the <code>&amp;</code> at the end of the command allows us to
keep working on the command line while having a graphical application
(such as <code>fsleyes</code>) opened. Helpful options for reviewing
fMRI data in fsleyes are the movie option ( <img src="../fig/movie_icon.png" alt="movie" height="24" class="figure"> ) and the timeseries
option (-&gt; view -&gt; timeseries or keyboard shortcut ⌘-3). Check
them out!</p>
</div>
<div class="section level3">
<h3 id="epi-distortion-correction">EPI Distortion Correction<a class="anchor" aria-label="anchor" href="#epi-distortion-correction"></a>
</h3>
<p>Some parts of the brain can appear distorted depending on their
magnetic properties. One common way to correct the distortions with fMRI
data is by acquiring one volume with an opposite phase-encoding
direction, and merging the two types of images running <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup" class="external-link">TOPUP</a>. In this
dataset we don’t have the data required for TOPUP so we will skip this
step. <em>Note however that you should run it if your data
allows.</em></p>
</div>
<div class="section level3">
<h3 id="preliminary-steps">Preliminary steps<a class="anchor" aria-label="anchor" href="#preliminary-steps"></a>
</h3>
<p>For some registrations steps we will need only one volume from our
fMRI timeseries. Run the following code to cut 1 volume in the middle of
the functional file:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="ex">fslroi</span> func/sub-OAS30015_task-rest_run-01_bold.nii.gz func/sub-OAS30015_task-rest_run-01_bold_1volume  80 1</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="motion-correction">Motion Correction<a class="anchor" aria-label="anchor" href="#motion-correction"></a>
</h3>
<p>A big issue in raw rs-fMRI scans is the fact that participants
usually tend to move during the length of the scanning session,
therefore producing artifacts in the images. Head motion results in
lower quality (more blurry) images, as well as creating spurious
correlations between voxels in the brain. Rs-fMRI pre-processing takes
care of the motion during the scan by realigning each volume within a
scan to a reference volume. The reference volume is usually the first or
the middle volume of the whole sequence.</p>
<p>To perform motion correction with fsl we use the <code>mcflirt</code>
command:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="ex">mcflirt</span> <span class="at">-in</span>  func/sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-out</span> func/mc_sub-OAS30015_task-rest_run-01_bold</span></code></pre>
</div>
<p>To keep track of what we are doing, it is good to add a prefix to the
output describing the preprocessing steps run on it. So in this case we
add <code>mc_</code> (motion corrected) to our original functional
file.</p>
<p>we can now have a look at original and motion corrected image by
typing</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">fsleyes</span> func/sub-OAS30015_task-rest_run-01_bold.nii.gz func/mc_sub-OAS30015_task-rest_run-01_bold <span class="kw">&amp;</span></span></code></pre>
</div>
<p>In <code>fsleyes</code> we can use the options in the lower left
panel to hide or move images up. Can you guess which are the spots of
the images that differ most between the two scans?</p>
</div>
<div class="section level3">
<h3 id="standard-space-mapping">Standard Space Mapping<a class="anchor" aria-label="anchor" href="#standard-space-mapping"></a>
</h3>
<p>Brain shape and size strongly vary across different individuals.
However, to perform group level analysis, voxels between different
brains need to correspond. This can be achieved by <em>registering</em>
or <em>normalizing</em> rs-fMRI scans in <em>native-space</em> to a
standard template. This processing step is actually made of three
different steps.</p>
<ol style="list-style-type: decimal">
<li>
<p>Compute the registration of the subject T1w scan to MNI
space:</p>
<p>This has been previously run using <code>flirt</code> and
<code>fnirt</code> (see above). The output transformation matrix is
stored in the <code>anat</code> subfolder and called
<code>highres2standard_warp.mat</code></p>
</li>
<li>
<p>Register the fMRI to the T1w file</p>
<p>With the following function we compute the transformation matrix
needed to bring the fMRI file to the T1w space</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="ex">epi_reg</span> <span class="at">--epi</span><span class="op">=</span>func/sub-OAS30015_task-rest_run-01_bold_1volume.nii.gz <span class="at">--t1</span><span class="op">=</span>anat/sub-OAS30015_T1w.nii.gz <span class="at">--t1brain</span><span class="op">=</span>anat/sub-OAS30015_T1w_bet.nii.gz <span class="at">--out</span><span class="op">=</span>func/func2highres</span></code></pre>
</div>
</li>
<li>
<p>Combine fMRI2T1w and T12MNI transformation, and apply in one go
to our timeseries</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># concatenate T12standard and fMRI2T1w affine transform</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="ex">convert_xfm</span> <span class="at">-omat</span> func/func2standard  <span class="at">-concat</span> anat/highres2standard.mat func/func2highres.mat  </span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co"># concatenate T12standard non-linear and fMRI2T1w affine transform</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="ex">convertwarp</span> <span class="at">--ref</span><span class="op">=</span><span class="va">$FSLDIR</span>/data/standard/MNI152_T1_2mm_brain <span class="at">--premat</span><span class="op">=</span>func/func2highres.mat <span class="at">--warp1</span><span class="op">=</span>anat/highres2standard_warp <span class="at">--out</span><span class="op">=</span>func/func2standard_warp </span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="ex">applywarp</span> <span class="at">--ref</span><span class="op">=</span><span class="va">$FSLDIR</span>/data/standard/MNI152_T1_2mm_brain <span class="at">--in</span><span class="op">=</span>func/mc_sub-OAS30015_task-rest_run-01_bold.nii.gz  <span class="at">--out</span><span class="op">=</span>func/MNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz  <span class="at">--warp</span><span class="op">=</span>func/func2standard_warp</span></code></pre>
</div>
</li>
</ol>
<p>The output of these functions is stored in
<code>func/MNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz</code> .
This is our fMRI scan in MNI space. You can check this by typing</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># check characteristics (dimensions) of the MNI functional file </span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="ex">fslinfo</span> func/MNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz  </span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># check characteristics (dimensions) of the native-space functional file </span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="ex">fslinfo</span> func/sub-OAS30015_task-rest_run-01_bold.nii.gz </span></code></pre>
</div>
<p>Let’s also have a look at the MNI file!</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="ex">fsleyes</span> func/MNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="kw">&amp;</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="spatial-smoothing">Spatial Smoothing<a class="anchor" aria-label="anchor" href="#spatial-smoothing"></a>
</h3>
<p>With spatial smoothing, we are referring to the process of averaging
the data points (voxels) with their neighbors. The downside of smoothing
is that we lose spatial specificity (resolution). However, this process
has the effect of a low-pass filter, removing high frequency and
enhancing low frequency. Moreover, spatial correlations within the data
are more pronounced and activation can be more easily detected.</p>
<p>In other words: Smoothing fMRI data increases signal-to-noise
ratio.</p>
<p>The standard procedure for spatial smoothing is applying a gaussian
function of a specific width, called the gaussian kernel. The size of
the gaussian kernel determines how much the data is smoothed and is
expressed as the Full Width at Half Maximum (FWHM). <img src="../fig/FWHM.png" alt="Example of full-with at half maximum" class="figure"></p>
<p>There is no standard value for smoothing fMRI data, FWHM usually
varies from 2mm to 8mm. A good compromise is to use a FWHM of 4. This
can be applied with <code>fslmaths</code> :</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="ex">fslmaths</span> func/MNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-s</span> 4 func/sMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz</span></code></pre>
</div>
<p>By changing the “-s” option we can change the FWHM, increasing or
decreasing the smoothing. Try it out and check the results with
<code>fsleyes</code>!</p>
</div>
<div class="section level3">
<h3 id="temporal-filtering">Temporal Filtering<a class="anchor" aria-label="anchor" href="#temporal-filtering"></a>
</h3>
<p>Rs-fMRI timeseries are also characterized by non-interesting
low-frequency drift due to physiological (e.g. respiration) or physical
(scanner-related) noise. For this reason, we usually apply an high-pass
filter that eliminates signal variations due to low-frequency. To do so,
a voxel timeseries can be represented in the frequency domain, and low
frequency can be set to 0.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="ex">fslmaths</span> func/sMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-bptf</span> 45.45 1 func/hpsMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="resting-state-networks-and-noise-components">Resting state Networks and Noise Components<a class="anchor" aria-label="anchor" href="#resting-state-networks-and-noise-components"></a>
</h3>
<p>Once the data is processed we can try to run an independent component
analysis (ICA) on the fMRI timeseries. ICA is usually performed for two
reasons: 1. Identify resting state networks, i.e. groups of areas that
covary (work) together. This step is often done at the group level. 2.
Identify further sources of noise from the data, and further remove them
(this is called denoising).</p>
<p>ICA can be run using the <code>melodic</code> command from FSL.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="ex">melodic</span> <span class="at">-i</span> func/hpsMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-o</span> func/ICA <span class="at">-m</span> /usr/local/fsl/data/standard/MNI152_T1_2mm_brain_mask.nii.gz</span></code></pre>
</div>
<p>The <code>-m</code> option specifies a mask that we want to run the
analysis in. In this case we use a standard brain mask provided by FSL
but you could also create your own mask using the structural
segmentation.</p>
<p>Melodic will create a directory called “ICA” in our func folder</p>
<p>Open the melodic_IC.nii.gz file in the output folder using
<code>fsleyes</code>, threshold the values to 3 (this value is commonly
used as a threshold for this task).</p>
<p>Now chose a nice colormap (usually red) and overlay this to a
standard brain template (-&gt; File -&gt; Add Standard).</p>
<p>Can you recognize some of the canonical resting-state networks?</p>
<figure><img src="../fig/RSN.png" alt="Output components from FSL Melodic" class="figure mx-auto d-block"></figure><p>Do you see some components that you think might be linked to
artefacts?</p>
<p>You can clean the original signal by writing them down and
running:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">fslregfilt</span> <span class="at">-i</span> func/sMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-o</span> func/denosised_sMNI_mc_sub-OAS30015_task-rest_run-01_bold.nii.gz <span class="at">-d</span> func/ICA/melodic_mix <span class="at">-f</span> <span class="st">" 1,2,3"</span></span></code></pre>
</div>
<p>with the <code>-f</code> option you can specify the components number
that you want to clean from the signal.</p>
</div>
</section><section><h2 class="section-heading" id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<hr class="half-width">
<p>You should now be able to fully process one fMRI scan yourself! As
you know, we usually work with a bunch of data and want to automatize
the pre-processing for all the scans, so that we can run it in one
go.</p>
<p>Also following the other sections of this course, try to put all
these commands in a <em>for</em> loop and use variables to run commands
on your files.</p>
<p>If you want to discover some type of analysis that you can do on the
processed data, check out some of these websites:</p>
<ul>
<li>
<a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets" class="external-link">FSLnets</a>
for network analysis of fMRI scans</li>
<li>
<a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MELODIC" class="external-link">Melodic
ICA</a> and <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/DualRegression" class="external-link">Dual
regression</a> for resting-state network connectivity</li>
<li>Graph Analysis of connectivity metrics with <a href="https://sites.google.com/site/bctnet/" class="external-link">Brain COnnectivity
Toolbox</a>
</li>
</ul>
<p>Ciao!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>fMRI measures small signal fluctations associated with
oxyhaemoglobin in the blood resulting from brain activation</li>
<li>Images can either be acquired during a task or with no task involved
(resting state)</li>
<li>Key preprocessing steps include: EPI distortion correction, brain
masking, smoothing, and temporal fitering</li>
<li>Network components extracted from techniques like Melodic can show
key network components, but also potentially components that represent
noise.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-command-line"><p>Content from <a href="command-line.html">Extra: Using the Command Line</a></p>
<hr>
<p>Last updated on 2024-07-23 |

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/episodes/command-line.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 12 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the command line interface?</li>
<li>Why is it helpful in neuroimaging analysis?</li>
<li>What are some common commands that I need to know?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Discover how to interact with files and directories on the command
line</li>
<li>Identify benefits that the command line can provide in processing
image data.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction-why-use-the-command-line">Introduction: Why use the command line?<a class="anchor" aria-label="anchor" href="#introduction-why-use-the-command-line"></a>
<a class="anchor" aria-label="anchor" href="#introduction-why-use-the-command-line"></a>
</h2>
<hr class="half-width">
<p>In order to get started with neuroimaging analysis, it is really
helpful to first understand how to interact with a computer on the
command line called the shell. At first look, it’s pretty bare bones and
minimalist. How can this simple way of interacting with a computer be so
useful?</p>
<figure><img src="../fig/CommandLine.png" alt="Picture of the command line" class="figure mx-auto d-block"></figure><p>Nowadays, we usually interact with a computer using a <em>Graphical
User Interface</em> or a GUI. These include programs like Word, Chrome,
iTunes which allow you to interact using your mouse to press buttons,
select options, move sliders, change values, etc. It provides a simple,
intuitive way for us to access the essential functionality that we need
from these programs. Some neuroimaging analysis software does comes with
a GUI, like this one from the <a href="https://www.fil.ion.ucl.ac.uk/spm/" class="external-link">Statistical Parametric Mapping
(SPM)</a> toolbox, a popular MATLAB based package.</p>
<figure><img src="../fig/spm_gui.jpg" alt="Example of the SPM GUI" class="figure mx-auto d-block"></figure><div class="section level3">
<h3 id="benefits-of-the-command-line">Benefits of the command line<a class="anchor" aria-label="anchor" href="#benefits-of-the-command-line"></a>
</h3>
<p>While GUIs are often the best way to interact with your computer,
using the command line for neuroimaging analysis is tremendously
powerful for many reasons:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Automation</strong> GUIs typically will wait until you tell
them what to do. When you go home at night, it won’t do anything because
it has no instructions! You can setup the command line to automate some
tasks so that it works late in the night while you are sleeping.</li>
<li>
<strong>Scalability</strong> Working with a GUI often means a lot of
mouse moves and clicks. For a small handful of imaging sessions, this is
a fine way to work, but what if your research project has
<em>hundreds</em> of datasets to process. It’s far more likely that an
error could occur or a dataset is missed. While you go through the
lessons in this workshop, count the number of mouse clicks it takes you
to do a task and think about how that would scale to your project. When
you run on the command line it has all of the information it needs, so
no interaction is needed, saving a lot of your time.</li>
<li>
<strong>Control</strong> With GUIs, you have access to the
functionality that the GUI provides you. However, hidden from the GUI
may be more advanced options that you need for your research. For the
sake of more software that is often more user-friendly for the majority
of tasks you are looking to do, the GUI can sometimes be restritie. With
the command line, you should have access to more, if not all, of the
functionality that the software provides, and thus more control over how
the task is run. It may take some investigation on your part,
though.</li>
<li>
<strong>Interoperability</strong> You may find that you want to take
results from one program and feed them into another and then another.
With GUI’s this often means saving or exporting the results, then
opening up the other program and importing them. The command line often
allows you the means to piece these steps together in one set of
instructions.</li>
</ol>
</div>
</section><section><h2 class="section-heading" id="getting-started">Getting started<a class="anchor" aria-label="anchor" href="#getting-started"></a>
<a class="anchor" aria-label="anchor" href="#getting-started"></a>
</h2>
<hr class="half-width">
<p>In this section, we are going to go through some basic steps of
working with the command line. Make sure you are able to connect to your
working environment by following the directions in the <a href="index.html#setup">Setup</a> section of this website. As a reminder, you
should have a desktop on your virtual machine that looks something like
this: <img src="../fig/aic_smri_desktop.png" alt="Screenshot of the VM desktop" class="figure"> Click on the
<code>Applications</code> icon in the top left of the window, and you
should see a taskbar pop out on the left-hand side. One of the icons is
a black box with a white border. This icon will launch the
<code>Terminal</code> and give you access to the command line. <img src="../fig/aic_smri_launch_terminal.png" alt="Launching a terminal" class="figure"></p>
</section><section><h2 class="section-heading" id="navigating-the-file-structure">Navigating the file structure<a class="anchor" aria-label="anchor" href="#navigating-the-file-structure"></a>
<a class="anchor" aria-label="anchor" href="#navigating-the-file-structure"></a>
</h2>
<hr class="half-width">
<p>The terminal should produce a window with a white background and
black text. This is the shell. We will enter some commands and see what
responses that the computer provdes. <img src="../fig/aic_smri_terminal_window.png" alt="Picture of an open terminal" class="figure"></p>
<ol style="list-style-type: decimal">
<li>
<p>The first thing we are going to do is figure out our present
location in the file system of the computer. We do that using the
command <code>pwd</code> which stands for <em>present working
directory</em>. Type it in the command line and see what the response
is:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">pwd</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>/home/as2-streaming-user</code></pre>
</div>
<p>This directory is also known as your <em>home directory</em></p>
</li>
<li>
<p>Next we are going to see what items are contained in this
directory. To do that, simply type <code>ls</code> and it should show
you all the files.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">ls</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Background.png  data  MyFiles  test</code></pre>
</div>
<p>You will notice that some of the entries are different colors. The
colors indicate whether the entries are files or directories. They also
can indicate if these files or directories have special
properties.</p>
</li>
<li>
<p>If we want more information about these files and directories,
then we can use the same command with a <em>command line option</em>
<code>-l</code> to tell the computer to list the files in a long
format</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-l</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>total 60
-rw-r--r-- 1 as2-streaming-user as2-streaming-user 57734 Jun 28  2023 Background.png
drwxrwxrwx 8 as2-streaming-user as2-streaming-user   142 Jun 22  2023 data
drwxr-xr-x 2 as2-streaming-user as2-streaming-user    46 Jul  8 22:31 MyFiles
drwxr-xr-x 2 as2-streaming-user as2-streaming-user     6 Jun 16  2023 test</code></pre>
</div>
<p>This now gives a lot more information, with the letters before the
file telling us about who owns the file (3rd and 4th column), what
permissions they have to read, write or run (execute) the file (first
column),and when it was modified (6th column).</p>
<p>If you want to list the contents of a different directory, just put
it after the <code>ls -l</code></p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-l</span> data</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>total 8
drwxr-xr-x 6 as2-streaming-user as2-streaming-user   84 Jun 16  2023 DiffusionMRI
drwxr-xr-x 2 as2-streaming-user as2-streaming-user 4096 Jul  4  2023 ExtraStructuralMRI
drwxr-xr-x 3 as2-streaming-user as2-streaming-user   26 Jun 27  2023 FunctionalMRI
drwxr-xr-x 2 as2-streaming-user as2-streaming-user 4096 Jun 16  2023 ImageDataVisualization
drwxr-xr-x 5 as2-streaming-user as2-streaming-user   77 Jul  7  2023 PETImaging
drwxr-xr-x 2 as2-streaming-user as2-streaming-user  120 Jun 27  2023 StructuralMRI</code></pre>
</div>
</li>
<li>
<p>The <code>data</code> directory is a sub-directory within your
home directory where you will be storing your work. So let us move into
that directory using the <code>cd</code> or <em>change directory</em>
command:</p>
<pre><code>cd data</code></pre>
<p>Now type the command <code>pwd</code> again. Has the result
changed?</p>
<p>What happens when we list the contents of this directory?</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-l</span></span></code></pre>
</div>
<p>You should get the same result as when you ran
<code>ls -l data</code> from your home directory.</p>
</li>
<li>
<p>Inside the data directory, let’s create a new directory that we
will call <code>mywork</code>. We do that using a command called
<code>mkdir</code>,</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">mkdir</span> mywork</span></code></pre>
</div>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#discussion1"></a>
</h3>
<div class="callout-content">
<p>Run the <code>ls</code> command again to see how the contents have
now changed to show your new directory.</p>
</div>
</div>
</div>
</li>
</ol>
<div class="section level3">
<h3 id="absolute-versus-relative-paths">Absolute versus Relative Paths<a class="anchor" aria-label="anchor" href="#absolute-versus-relative-paths"></a>
</h3>
<p>Locations in the file system, whether they are files or directories,
are known as paths. Paths can be referred to in <em>absolute</em> terms
(like a postal address or latitude and longitude) or <em>relative</em>
terms (like directions to your work from home). In some cases it is more
convenient to use absolute paths, and in others, relative paths are
nicer. Absolute paths always begin with a <code>/</code> character. From
your home directory, the following two commands do the exact same
thing.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Using an absolute path - this will work anywhere</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">ls</span> /home/as2-streaming-user/data</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>DiffusionMRI        FunctionalMRI           mywork      StructuralMRI
ExtraStructuralMRI  ImageDataVisualization  PETImaging</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Using a relative path - this will only work if you are in the </span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co"># directory where data is located</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="fu">ls</span> data</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>DiffusionMRI        FunctionalMRI           mywork      StructuralMRI
ExtraStructuralMRI  ImageDataVisualization  PETImaging</code></pre>
</div>
</div>
<div class="section level3">
<h3 id="helpful-hints">Helpful hints<a class="anchor" aria-label="anchor" href="#helpful-hints"></a>
</h3>
<ul>
<li>
<p><strong>Feeling lost?</strong> You can always get back to your
home directory simply by typing <code>cd</code> without any arguments or
by using the tilde symbol, which is the shortcut for home.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="bu">cd</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="bu">cd</span> ~</span></code></pre>
</div>
</li>
<li>
<p><strong>Help me!</strong> If you want to know more about a
command, just type <code>man</code> in front of it to get the <em>manual
entry</em>.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">man</span> ls</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">man</span> find</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="fu">man</span> more</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="fu">man</span> less</span></code></pre>
</div>
</li>
<li><p><strong>Previous commands</strong> If you want to see a list of
commands that you have run, you can type in the <code>history</code>
command. You can also scroll through previous commands by tapping the up
and down arrow keys and then hit Return when you found the command you
want to run again.</p></li>
</ul>
</div>
</section><section><h2 class="section-heading" id="processing-files">Processing files<a class="anchor" aria-label="anchor" href="#processing-files"></a>
<a class="anchor" aria-label="anchor" href="#processing-files"></a>
</h2>
<hr class="half-width">
<p>In this section, we will go over how to copy and view the contents of
the files. There is some helpful information about one of the images in
our Structural MRI lesson that we want to look at in more detail.</p>
<ol style="list-style-type: decimal">
<li>
<p>Let’s copy it over from the directory it is currently located
into our new <code>mywork</code> directory. We do this using the
<code>cp</code> or <em>copy</em> command. We first specify the
<em>source</em>, or the file/directory that we want to copy
(<code>data/StructuralMRI/sub-OAS30003_T1w.json</code>), and then we
specify the destination path where we want to make the copy
(<code>data/mywork</code>). <strong>Before we do this command, let’s
make sure we are back in the home directory first</strong></p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Go back to the home directory</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="bu">cd</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="co"># Copy the file.</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="fu">cp</span> data/StructuralMRI/sub-OAS30003_T1w.json data/mywork</span></code></pre>
</div>
</li>
<li>
<p>Now let us confirm that the copy of the file is where we expect
it to be:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">ls</span> data/mywork/</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="va">sub</span><span class="op">-</span><span class="va">OAS30003_T1w.json</span></span></code></pre>
</div>
</li>
<li>
<p>Finally, let’s look at the contents of the file. We can do that
with the command <code>cat</code> which concatenates and prints
files.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">cat</span> data/mywork/sub-OAS_30003_T1w.json </span></code></pre>
</div>
</li>
</ol>
<div id="accordionSpoiler1" class="accordion spoiler-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button spoiler-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSpoiler1" aria-expanded="false" aria-controls="collapseSpoiler1">
  <h3 class="accordion-header" id="headingSpoiler1">
  <div class="note-square"><i aria-hidden="true" class="callout-icon" data-feather="eye"></i></div>
  That just flew off the screen!
  </h3>
</button>
<div id="collapseSpoiler1" class="accordion-collapse collapse" data-bs-parent="#accordionSpoiler1" aria-labelledby="headingSpoiler1">
<div class="accordion-body">
<p>Using <code>cat</code> on a large text file can end up looking
impressive as text swarms all over your terminal, but it can be hard to
examine the file…</p>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>{
    "Modality": "MR",
    "MagneticFieldStrength": 3,
    "Manufacturer": "Siemens",
    "ManufacturersModelName": "Biograph_mMR",
    "DeviceSerialNumber": "51010",
    "PatientPosition": "HFS",
    "SoftwareVersions": "syngo_MR_B18P",
    "MRAcquisitionType": "3D",
    "SeriesDescription": "MPRAGE_GRAPPA2",
    "ScanningSequence": "GR_IR",
    "SequenceVariant": "SP_MP",
    "ScanOptions": "IR",
    "SequenceName": "_tfl3d1_ns",
    "ImageType": [
        "ORIGINAL",
        "PRIMARY",
        "M",
        "ND",
        "NORM"
    ],
    "AcquisitionTime": "11:53:18.945000",
    "AcquisitionNumber": 1,
    "SliceThickness": 1.2,
    "SAR": 0.0397884,
    "EchoTime": 0.00295,
    "RepetitionTime": 2.3,
    "InversionTime": 0.9,
    "FlipAngle": 9,
    "PartialFourier": 1,
    "BaseResolution": 256,
    "ShimSetting": [
        -6853,
        14225,
        -5859,
        -89,
        -201,
        157,
        585,
        -236
    ],
    "TxRefAmp": 307.072,
    "PhaseResolution": 1,
    "ReceiveCoilName": "HeadNeck_MRPET",
    "PulseSequenceDetails": "%SiemensSeq%_tfl",
    "PercentPhaseFOV": 93.75,
    "PhaseEncodingSteps": 239,
    "AcquisitionMatrixPE": 240,
    "ReconMatrixPE": 256,
    "ParallelReductionFactorInPlane": 2,
    "PixelBandwidth": 238,
    "DwellTime": 8.2e-06,
    "ImageOrientationPatientDICOM": [
        0,
        1,
        0,
        0,
        0,
        -1
    ],
    "InPlanePhaseEncodingDirectionDICOM": "ROW",
    "ConversionSoftware": "dcm2niix",
    "ConversionSoftwareVersion": "v1.0.20171017 GCC4.4.7"</code></pre>
</div>
<p>If we want to have a bit more control over how we view larger files,
then we can use either the <code>more</code> or <code>less</code>
command. This allows you to scroll through the file a line or page at a
time, go back, search the text, etc.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="fu">more</span> data/mywork/sub-OAS_30003_T1w.json </span></code></pre>
</div>
</div>
</div>
</div>
</div>
<ol style="list-style-type: decimal">
<li>
<p>We no longer need that file anymore (remember it is just a copy),
so we can remove files by using the <code>rm</code> command, but
<strong>BE CAREFUL</strong> and check the command twice before executing
the command, as this cannot be undone! Watch out for any spaces or any
special characters like the <code>*</code> and <code>?</code> as they
mean something special in the shell, and including them in a remove
command may remove more files than you intended.</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">rm</span> data/mywork/sub-OAS_30003_T1w.json </span></code></pre>
</div>
</li>
</ol></section><section><h2 class="section-heading" id="further-reading">Further reading<a class="anchor" aria-label="anchor" href="#further-reading"></a>
<a class="anchor" aria-label="anchor" href="#further-reading"></a>
</h2>
<hr class="half-width">
<p>If you want to find out more how to use the command line, please
check out the following helpful resources:</p>
<ul>
<li><a href="https://swcarpentry.github.io/shell-novice/" class="external-link">“The Unix
Shell” Software Carpentry lesson</a></li>
<li><a href="https://tldp.org/LDP/Bash-Beginners-Guide/html" class="external-link">Bash guide
for beginners</a></li>
</ul></section><section><h2 class="section-heading" id="stretch-exercises">Stretch exercises<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
<a class="anchor" aria-label="anchor" href="#stretch-exercises"></a>
</h2>
<hr class="half-width">
<p>As you get more comfortable, you can start to do powerful things with
the command line.</p>
<div id="variables" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="variables" class="callout-inner">
<h3 class="callout-title">Variables<a class="anchor" aria-label="anchor" href="#variables"></a>
</h3>
<div class="callout-content">
<p>Sometimes we want to store some information for future use. We can do
that with a variable. A variable has a name and a value. A variable in
the shell can hold a number, a single character, a word, sentence or a
list of things. You <em>assign</em> a value to a variable with a simple
statement <code>var=value</code> where you replace var with the name
that you want to call the variable and replace value with the value you
want to store. Once the variable has been assigned, you can access the
value within the variable by putting a <code>$</code> in front of the
variable name</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="va">image</span><span class="op">=</span><span class="st">"T1"</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"My favorite images are </span><span class="va">$image</span><span class="st"> scans."</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>My favorite images are T1 scans.</code></pre>
</div>
<p>See how it replaces <code>$image</code> with T1. Let’s do it again
and assign a new value to <code>image</code>.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="va">image</span><span class="op">=</span><span class="st">"DTI"</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"My favorite images are </span><span class="va">$image</span><span class="st"> scans."</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>My favorite images are DTI scans.</code></pre>
</div>
</div>
</div>
</div>
<div id="looping" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="looping" class="callout-inner">
<h3 class="callout-title">Looping<a class="anchor" aria-label="anchor" href="#looping"></a>
</h3>
<div class="callout-content">
<p>Variables are really helpful when we want to set up a loop. Let’s say
we have images from 100 different subjects who are in our study, and we
want to make sure that we process each of the images in the exact same
way. You could type the commands out 100 times, where in each set of
commands, you change the name of the image files. As you could imagine,
that would be really boring, and there is definitely more risk of an
error being introduced. A loop is a solution to this and makes your
command writing much simpler. It is simply an instruction to the shell
that says run the same command a bunch of times.</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> David Ludovica Tobey Alexa Luigi</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a><span class="cf">do</span></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>    <span class="bu">echo</span> <span class="st">"Hey </span><span class="va">${name}</span><span class="st">, I need help!"</span></span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="cf">done</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Hey David, I need help!
Hey Ludovica, I need help!
Hey Tobey, I need help!
Hey Alexa, I need help!
Hey Luigi, I need help!</code></pre>
</div>
<p>Here, the loop is setup with a <code>for</code> command, with the
format <code>for (var) in (list)</code> where (var) is the <em>variable
name</em>, and its value will change with each iteration of the loop and
(list) holds the list of entries that you want to loop over. The for
loop will determine how many entries are in the list. At each iteration,
it will place the next value of the list in to the variable (in our
example <code>name</code>) and execute the commands that are inside the
keywords <code>do</code> (start the loop) and <code>done</code> (end the
loop).</p>
</div>
</div>
</div>
<div id="redirection" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="redirection" class="callout-inner">
<h3 class="callout-title">Redirection<a class="anchor" aria-label="anchor" href="#redirection"></a>
</h3>
<div class="callout-content">
<p>Quite often, when you execute a command on the shell, it prints out
information on the screen that is useful to store for later. You can
store them in the file using <em>redirection</em>. The <code>&gt;</code>
says redirects the output from the screen to another location, such as a
file, overwriting the current contents. The <code>&gt;&gt;</code> does
the same thing but it just appends the contents at the end. This loop
just prints the number and its square on the screen.</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> 1 2 3 4 5 6 7 8 9 10</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a><span class="cf">do</span> </span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>    <span class="bu">let</span> <span class="va">j</span><span class="op">=</span><span class="va">i</span><span class="pp">*</span>i</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a>    <span class="bu">echo</span> <span class="va">$i</span> <span class="va">$j</span></span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a><span class="cf">done</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1 1
2 4
3 9
4 16
5 25
6 36
7 49
8 64
9 81
10 100</code></pre>
</div>
<p>This loop does the same thing but saves it to a text file called
<code>squares.txt</code></p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> 1 2 3 4 5 6 7 8 9 10</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a><span class="cf">do</span> </span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>    <span class="bu">let</span> <span class="va">j</span><span class="op">=</span><span class="va">i</span><span class="pp">*</span>i</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a>    <span class="bu">echo</span> <span class="va">$i</span> <span class="va">$j</span> <span class="op">&gt;&gt;</span> squares.txt</span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a><span class="cf">done</span></span></code></pre>
</div>
<p>Now if we show the contents of <code>squares.txt</code>, we see it
has the same information.</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="fu">cat</span> squares.txt</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1 1
2 4
3 9
4 16
5 25
6 36
7 49
8 64
9 81
10 100</code></pre>
</div>
<p>Redirection can also be used for getting input using the
<code>&lt;</code> character. This finds the line where 64 is the
answer.</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="fu">grep</span> 64 <span class="op">&lt;</span> squares.txt</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>8 64</code></pre>
</div>
<p>Finally you can redirect output from one command into input of
another command using the pipe character, <code>|</code>. In this case
we are directing the output from the <code>echo</code> command from the
screen to the input of the calculator command <code>bc</code>.</p>
<div class="codewrapper sourceCode" id="cb38">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"242*242"</span> <span class="kw">|</span> <span class="fu">bc</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">58564</span></span></code></pre>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="command-line-cheatsheet">Command line cheatsheet<a class="anchor" aria-label="anchor" href="#command-line-cheatsheet"></a>
<a class="anchor" aria-label="anchor" href="#command-line-cheatsheet"></a>
</h2>
<hr class="half-width">
<table class="table">
<colgroup>
<col width="25%">
<col width="25%">
<col width="25%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th>Command</th>
<th>Name</th>
<th>Function</th>
<th>Example Usage</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>man</td>
<td>Manual</td>
<td>HELP!</td>
<td><code>man cd</code></td>
</tr>
<tr class="even">
<td>pwd</td>
<td>Print working directory</td>
<td>Where am I?</td>
<td><code>pwd</code></td>
</tr>
<tr class="odd">
<td>mkdir</td>
<td>Make directory</td>
<td>Create a new directory</td>
<td><code>mkdir dir1</code></td>
</tr>
<tr class="even">
<td>cd</td>
<td>Change directory</td>
<td>Go to the following location</td>
<td><code>cd dir1</code></td>
</tr>
<tr class="odd">
<td>ls</td>
<td>List</td>
<td>Shows what is inside a directory</td>
<td><code>ls dir1</code></td>
</tr>
<tr class="even">
<td>cp</td>
<td>Copy</td>
<td>Copies a source file to a new destination</td>
<td><code>cp src dest</code></td>
</tr>
<tr class="odd">
<td>mv</td>
<td>Move</td>
<td>Moves a source file to a new destination</td>
<td><code>mv source destination</code></td>
</tr>
<tr class="even">
<td>rm</td>
<td>Remove</td>
<td>Deletes a file or a directory</td>
<td><code>rm dir1/bad_file</code></td>
</tr>
<tr class="odd">
<td>cat</td>
<td>Concatenate</td>
<td>Prints out the contents of a file</td>
<td><code>cat results.txt</code></td>
</tr>
<tr class="even">
<td>more</td>
<td>more</td>
<td>Prints out the contents of a file. Better for large files to
scroll</td>
<td><code>more results.txt</code></td>
</tr>
<tr class="odd">
<td>nano, emacs, gedit</td>
<td>Text editor</td>
<td>Programs that edit plain text files (no formatting)</td>
<td>
<code>emacs dir1/inputs.txt</code>
<code>nano dir1/inputs.txt</code>
</td>
</tr>
</tbody>
</table>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>The command line interface is a low-level way of interacting with
your computer</li>
<li>It provides more control, more reliability, and more scalability
than manually interacting with a graphical user interface.</li>
<li>Paths can be specified in two ways: an <em>absolute</em> path and a
<em>relative</em> path. The absolute path remains the same regardless of
the current location, where the relative path will change.</li>
<li>Help can be found by typing the man command</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/" class="external-link">Source</a></p>
				<p><a href="https://github.com/HealthBioscienceIDEAS/aaic2024-neuroimaging-workshop/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:d.cash@ucl.ac.uk">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/HealthBioscienceIDEAS/sandpaper/tree/IDEAS" class="external-link">sandpaper (0.16.5)</a>, <a href="https://github.com/carpentries/pegboard/tree/ad2542f7f7b9c3f90cc871b355ff81ec14a09ca9" class="external-link">pegboard (0.7.6)</a>, and <a href="https://github.com/HealthBioscienceIDEAS/varnish/tree/IDEAS" class="external-link">varnish (1.0.3.9000)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://HealthBioscienceIDEAS.github.io/aaic2024-neuroimaging-workshop/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "medical imaging, MRI, visualization, PET, Alzheimers disease",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://HealthBioscienceIDEAS.github.io/aaic2024-neuroimaging-workshop/instructor/aio.html",
  "identifier": "https://HealthBioscienceIDEAS.github.io/aaic2024-neuroimaging-workshop/instructor/aio.html",
  "dateCreated": "2024-06-04",
  "dateModified": "2024-07-23",
  "datePublished": "2024-07-23"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

